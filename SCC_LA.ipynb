{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/PerceptionComputingLab/SCC/blob/main/code/train_LA_semi_contrastive.py"
      ],
      "metadata": {
        "id": "XlF26-MfppFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "0UxPggoI4X6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "id": "5iNkUeHUMC9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medpy"
      ],
      "metadata": {
        "id": "uPF-3tOMMC_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/2018LA_Seg_Training Set.zip'"
      ],
      "metadata": {
        "id": "mW2zRzIF3pUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/SCC_6.zip'"
      ],
      "metadata": {
        "id": "qni5VKKLQsM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, norm\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.conv import Conv3d\n",
        "from torch.distributions.uniform import Uniform\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, n_stages, n_filters_in, n_filters_out, normalization='none', isrec=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        if isrec:\n",
        "            normalization = 'batchnorm'\n",
        "        ops = []\n",
        "        for i in range(n_stages):\n",
        "            if i==0:\n",
        "                input_channel = n_filters_in\n",
        "            else:\n",
        "                input_channel = n_filters_out\n",
        "\n",
        "            ops.append(nn.Conv3d(input_channel, n_filters_out, 3, padding=1))\n",
        "            if normalization == 'batchnorm':\n",
        "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
        "            elif normalization == 'groupnorm':\n",
        "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
        "            elif normalization == 'instancenorm':\n",
        "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
        "            elif normalization != 'none':\n",
        "                assert False\n",
        "            ops.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv = nn.Sequential(*ops)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResidualConvBlock(nn.Module):\n",
        "    def __init__(self, n_stages, n_filters_in, n_filters_out, normalization='none'):\n",
        "        super(ResidualConvBlock, self).__init__()\n",
        "\n",
        "        ops = []\n",
        "        for i in range(n_stages):\n",
        "            if i == 0:\n",
        "                input_channel = n_filters_in\n",
        "            else:\n",
        "                input_channel = n_filters_out\n",
        "\n",
        "            ops.append(nn.Conv3d(input_channel, n_filters_out, 3, padding=1))\n",
        "            if normalization == 'batchnorm':\n",
        "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
        "            elif normalization == 'groupnorm':\n",
        "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
        "            elif normalization == 'instancenorm':\n",
        "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
        "            elif normalization != 'none':\n",
        "                assert False\n",
        "\n",
        "            if i != n_stages-1:\n",
        "                ops.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv = nn.Sequential(*ops)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (self.conv(x) + x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DownsamplingConvBlock(nn.Module):\n",
        "    def __init__(self, n_filters_in, n_filters_out, stride=2, normalization='none'):\n",
        "        super(DownsamplingConvBlock, self).__init__()\n",
        "\n",
        "        ops = []\n",
        "        if normalization != 'none':\n",
        "            ops.append(nn.Conv3d(n_filters_in, n_filters_out, stride, padding=0, stride=stride))\n",
        "            if normalization == 'batchnorm':\n",
        "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
        "            elif normalization == 'groupnorm':\n",
        "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
        "            elif normalization == 'instancenorm':\n",
        "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
        "            else:\n",
        "                assert False\n",
        "        else:\n",
        "            ops.append(nn.Conv3d(n_filters_in, n_filters_out, stride, padding=0, stride=stride))\n",
        "\n",
        "        ops.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv = nn.Sequential(*ops)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpsamplingDeconvBlock(nn.Module):\n",
        "    def __init__(self, n_filters_in, n_filters_out, stride=2, normalization='none',isrec=False):\n",
        "        super(UpsamplingDeconvBlock, self).__init__()\n",
        "        if isrec:\n",
        "            normalization='batchnorm'\n",
        "        ops = []\n",
        "        if normalization != 'none':\n",
        "            ops.append(nn.ConvTranspose3d(n_filters_in, n_filters_out, stride, padding=0, stride=stride))\n",
        "            if normalization == 'batchnorm':\n",
        "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
        "            elif normalization == 'groupnorm':\n",
        "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
        "            elif normalization == 'instancenorm':\n",
        "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
        "            else:\n",
        "                assert False\n",
        "        else:\n",
        "            ops.append(nn.ConvTranspose3d(n_filters_in, n_filters_out, stride, padding=0, stride=stride))\n",
        "\n",
        "        ops.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv = nn.Sequential(*ops)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Upsampling(nn.Module):\n",
        "    def __init__(self, n_filters_in, n_filters_out, stride=2, normalization='none'):\n",
        "        super(Upsampling, self).__init__()\n",
        "\n",
        "        ops = []\n",
        "        ops.append(nn.Upsample(scale_factor=stride, mode='trilinear',align_corners=False))\n",
        "        ops.append(nn.Conv3d(n_filters_in, n_filters_out, kernel_size=3, padding=1))\n",
        "        if normalization == 'batchnorm':\n",
        "            ops.append(nn.BatchNorm3d(n_filters_out))\n",
        "        elif normalization == 'groupnorm':\n",
        "            ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
        "        elif normalization == 'instancenorm':\n",
        "            ops.append(nn.InstanceNorm3d(n_filters_out))\n",
        "        elif normalization != 'none':\n",
        "            assert False\n",
        "        ops.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv = nn.Sequential(*ops)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class VNet_Encoder(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_filters=16, normalization='none', has_dropout=False):\n",
        "        super(VNet_Encoder, self).__init__()\n",
        "        self.has_dropout = has_dropout\n",
        "\n",
        "        self.block_one = ConvBlock(1, n_channels, n_filters, normalization=normalization)\n",
        "        self.block_one_dw = DownsamplingConvBlock(n_filters, 2 * n_filters, normalization=normalization)\n",
        "\n",
        "        self.block_two = ConvBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
        "        self.block_two_dw = DownsamplingConvBlock(n_filters * 2, n_filters * 4, normalization=normalization)\n",
        "\n",
        "        self.block_three = ConvBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
        "        self.block_three_dw = DownsamplingConvBlock(n_filters * 4, n_filters * 8, normalization=normalization)\n",
        "\n",
        "        self.block_four = ConvBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
        "        self.block_four_dw = DownsamplingConvBlock(n_filters * 8, n_filters * 16, normalization=normalization)\n",
        "\n",
        "        self.block_five = ConvBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
        "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input, turnoff_drop=False):\n",
        "        x1 = self.block_one(input)\n",
        "        x1_dw = self.block_one_dw(x1)\n",
        "\n",
        "        x2 = self.block_two(x1_dw)\n",
        "        x2_dw = self.block_two_dw(x2)\n",
        "\n",
        "        x3 = self.block_three(x2_dw)\n",
        "        x3_dw = self.block_three_dw(x3)\n",
        "\n",
        "        x4 = self.block_four(x3_dw)\n",
        "        x4_dw = self.block_four_dw(x4)\n",
        "\n",
        "        x5 = self.block_five(x4_dw)\n",
        "        if self.has_dropout:\n",
        "            x5 = self.dropout(x5)\n",
        "        res = [x1, x2, x3, x4, x5]\n",
        "        return res\n",
        "\n",
        "class MainDecoder(nn.Module):\n",
        "    def __init__(self,n_classes=2, n_filters=16, normalization='batchnorm', has_dropout=False):\n",
        "        super(MainDecoder, self).__init__()\n",
        "        self.has_dropout = has_dropout\n",
        "\n",
        "        self.block_five = ConvBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
        "        self.block_five_up = UpsamplingDeconvBlock(n_filters * 16, n_filters * 8, normalization=normalization)\n",
        "\n",
        "        self.block_six = ConvBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
        "        self.block_six_up = UpsamplingDeconvBlock(n_filters * 8, n_filters * 4, normalization=normalization)\n",
        "\n",
        "        self.block_seven = ConvBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
        "        self.block_seven_up = UpsamplingDeconvBlock(n_filters * 4, n_filters * 2, normalization=normalization)\n",
        "\n",
        "        self.block_eight = ConvBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
        "        self.block_eight_up = UpsamplingDeconvBlock(n_filters * 2, n_filters, normalization=normalization)\n",
        "\n",
        "        self.block_nine = ConvBlock(1, n_filters, n_filters, normalization=normalization)\n",
        "        self.out_conv = nn.Conv3d(n_filters, n_classes, 1, padding=0)\n",
        "\n",
        "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
        "\n",
        "    def forward(self, features):\n",
        "        x1 = features[0]\n",
        "        x2 = features[1]\n",
        "        x3 = features[2]\n",
        "        x4 = features[3]\n",
        "        x5 = features[4]\n",
        "\n",
        "        x5_up = self.block_five_up(x5)\n",
        "        x5_up = x5_up + x4\n",
        "\n",
        "        x6 = self.block_six(x5_up)\n",
        "        x6_up = self.block_six_up(x6)\n",
        "        x6_up = x6_up + x3\n",
        "\n",
        "        x7 = self.block_seven(x6_up)\n",
        "        x7_up = self.block_seven_up(x7)\n",
        "        x7_up = x7_up + x2\n",
        "\n",
        "        x8 = self.block_eight(x7_up)\n",
        "        x8_up = self.block_eight_up(x8)\n",
        "        x8_up = x8_up + x1\n",
        "        x9 = self.block_nine(x8_up)\n",
        "        if self.has_dropout:\n",
        "            x9 = self.dropout(x9)\n",
        "        out = self.out_conv(x9)\n",
        "        return out\n",
        "\n",
        "class SDMDecoder(nn.Module):\n",
        "    def __init__(self, n_filters=16, normalization='batchnorm', has_dropout=False):\n",
        "        super(SDMDecoder, self).__init__()\n",
        "        self.has_dropout = has_dropout\n",
        "\n",
        "        self.block_five = ConvBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
        "        self.block_five_up = UpsamplingDeconvBlock(n_filters * 16, n_filters * 8, normalization=normalization)\n",
        "\n",
        "        self.block_six = ConvBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
        "        self.block_six_up = UpsamplingDeconvBlock(n_filters * 8, n_filters * 4, normalization=normalization)\n",
        "\n",
        "        self.block_seven = ConvBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
        "        self.block_seven_up = UpsamplingDeconvBlock(n_filters * 4, n_filters * 2, normalization=normalization)\n",
        "\n",
        "        self.block_eight = ConvBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
        "        self.block_eight_up = UpsamplingDeconvBlock(n_filters * 2, n_filters, normalization=normalization)\n",
        "\n",
        "        self.block_nine = ConvBlock(1, n_filters, n_filters, normalization=normalization)\n",
        "        self.out_conv = nn.Conv3d(n_filters, 1, 1, padding=0)\n",
        "\n",
        "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
        "\n",
        "    def forward(self, features):\n",
        "        x1 = features[0]\n",
        "        x2 = features[1]\n",
        "        x3 = features[2]\n",
        "        x4 = features[3]\n",
        "        x5 = features[4]\n",
        "\n",
        "        x5_up = self.block_five_up(x5)\n",
        "        x5_up = x5_up + x4\n",
        "\n",
        "        x6 = self.block_six(x5_up)\n",
        "        x6_up = self.block_six_up(x6)\n",
        "        x6_up = x6_up + x3\n",
        "\n",
        "        x7 = self.block_seven(x6_up)\n",
        "        x7_up = self.block_seven_up(x7)\n",
        "        x7_up = x7_up + x2\n",
        "\n",
        "        x8 = self.block_eight(x7_up)\n",
        "        x8_up = self.block_eight_up(x8)\n",
        "        x8_up = x8_up + x1\n",
        "        x9 = self.block_nine(x8_up)\n",
        "        if self.has_dropout:\n",
        "            x9 = self.dropout(x9)\n",
        "        out = self.out_conv(x9)\n",
        "        return out\n",
        "\n",
        "class RecDecoder(nn.Module):\n",
        "    def __init__(self, n_filters=16, normalization='batchnorm', has_dropout=False):\n",
        "        super(RecDecoder, self).__init__()\n",
        "        self.has_dropout = has_dropout\n",
        "\n",
        "        self.block_five = ConvBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
        "        self.block_five_up = UpsamplingDeconvBlock(n_filters * 16, n_filters * 8, normalization=normalization)\n",
        "\n",
        "        self.block_six = ConvBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
        "        self.block_six_up = UpsamplingDeconvBlock(n_filters * 8, n_filters * 4, normalization=normalization)\n",
        "\n",
        "        self.block_seven = ConvBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
        "        self.block_seven_up = UpsamplingDeconvBlock(n_filters * 4, n_filters * 2, normalization=normalization)\n",
        "\n",
        "        self.block_eight = ConvBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
        "        self.block_eight_up = UpsamplingDeconvBlock(n_filters * 2, n_filters, normalization=normalization)\n",
        "\n",
        "        self.block_nine = ConvBlock(1, n_filters, n_filters, normalization=normalization)\n",
        "        self.out_rec_conv_2 = nn.Conv3d(n_filters, 2, 1, padding=0)\n",
        "        self.out_rec_conv_1 = nn.Conv3d(n_filters, 1, 1, padding=0)\n",
        "\n",
        "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
        "\n",
        "    def forward(self, features):\n",
        "\n",
        "        x1 = features[0]\n",
        "        x2 = features[1]\n",
        "        x3 = features[2]\n",
        "        x4 = features[3]\n",
        "        x5 = features[4]\n",
        "\n",
        "        x5_up = self.block_five_up(x5)\n",
        "        x5_up = x5_up + x4\n",
        "\n",
        "        x6 = self.block_six(x5_up)\n",
        "        x6_up = self.block_six_up(x6)\n",
        "        x6_up = x6_up + x3\n",
        "\n",
        "        x7 = self.block_seven(x6_up)\n",
        "        x7_up = self.block_seven_up(x7)\n",
        "        x7_up = x7_up + x2\n",
        "\n",
        "        x8 = self.block_eight(x7_up)\n",
        "        x8_up = self.block_eight_up(x8)\n",
        "        x8_up = x8_up + x1\n",
        "        x9 = self.block_nine(x8_up)\n",
        "        if self.has_dropout:\n",
        "            x9 = self.dropout(x9)\n",
        "        out = self.out_rec_conv_2(x9)\n",
        "        return out\n",
        "\n",
        "class TriupDecoder(nn.Module):\n",
        "    def __init__(self, n_classes=2, n_filters=16, normalization='batchnorm', has_dropout=False):\n",
        "        super(TriupDecoder, self).__init__()\n",
        "        self.has_dropout = has_dropout\n",
        "\n",
        "        self.block_five = ConvBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
        "        self.block_five_up = Upsampling(n_filters * 16, n_filters * 8, normalization=normalization)\n",
        "\n",
        "        self.block_six = ConvBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
        "        self.block_six_up = Upsampling(n_filters * 8, n_filters * 4, normalization=normalization)\n",
        "\n",
        "        self.block_seven = ConvBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
        "        self.block_seven_up = Upsampling(n_filters * 4, n_filters * 2, normalization=normalization)\n",
        "\n",
        "        self.block_eight = ConvBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
        "        self.block_eight_up = Upsampling(n_filters * 2, n_filters, normalization=normalization)\n",
        "\n",
        "        self.block_nine = ConvBlock(1, n_filters, n_filters, normalization=normalization)\n",
        "        self.out_conv = nn.Conv3d(n_filters, n_classes, 1, padding=0)\n",
        "\n",
        "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
        "\n",
        "    def forward(self, features):\n",
        "        x1 = features[0]\n",
        "        x2 = features[1]\n",
        "        x3 = features[2]\n",
        "        x4 = features[3]\n",
        "        x5 = features[4]\n",
        "\n",
        "        x5_up = self.block_five_up(x5)\n",
        "        x5_up = x5_up + x4\n",
        "\n",
        "        x6 = self.block_six(x5_up)\n",
        "        x6_up = self.block_six_up(x6)\n",
        "        x6_up = x6_up + x3\n",
        "\n",
        "        x7 = self.block_seven(x6_up)\n",
        "        x7_up = self.block_seven_up(x7)\n",
        "        x7_up = x7_up + x2\n",
        "\n",
        "        x8 = self.block_eight(x7_up)\n",
        "        x8_up = self.block_eight_up(x8)\n",
        "        x8_up = x8_up + x1\n",
        "        x9 = self.block_nine(x8_up)\n",
        "        if self.has_dropout:\n",
        "            x9 = self.dropout(x9)\n",
        "        out = self.out_conv(x9)\n",
        "        return out\n",
        "\n",
        "\n",
        "class center_model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, ndf=64, out_channel=1):\n",
        "        super(center_model, self).__init__()\n",
        "        # downsample 16\n",
        "        self.conv0 = nn.Conv3d(1, ndf, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv1 = nn.Conv3d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv3d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv3d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
        "        self.avgpool = nn.AvgPool3d((5, 7, 7))\n",
        "        self.fc1 = nn.Linear(ndf*8, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        self.dropout = nn.Dropout3d(0.5)\n",
        "        self.Softmax = nn.Softmax()\n",
        "        self.out = nn.Conv3d(ndf*2,num_classes,kernel_size=1)\n",
        "    def forward(self, map):\n",
        "        batch_size = map.shape[0]\n",
        "        map_feature = self.conv0(map)#(2,112,112,80)->(64,56,56,40)\n",
        "        x = self.leaky_relu(map_feature)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv1(x)#(64,56,56,40)->(128,28,28,20)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.dropout(x)\n",
        "        #x = self.out(x)\n",
        "\n",
        "        x = self.conv2(x)#(128,28,28,20)->(256,14,14,10)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x)#(256,14,14,10)->(512,7,7,5)\n",
        "        x = self.leaky_relu(x)\n",
        "\n",
        "        x = self.avgpool(x)#(512)\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "oWKpCD0J2euf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX7nixf3pnuH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "from scipy.ndimage import rotate\n",
        "import itertools\n",
        "from torch.utils.data.sampler import Sampler\n",
        "import sys\n",
        "\n",
        "# code ref: https://github.com/JunMa11/SegWithDistMap/tree/master/code/dataloaders\n",
        "#\n",
        "class LAHeart(Dataset):\n",
        "    \"\"\" LA Dataset \"\"\"\n",
        "    def __init__(self, base_dir=None, split='train', num=None, transform=None):\n",
        "        self._base_dir = base_dir\n",
        "        self.transform = transform\n",
        "        self.sample_list = []\n",
        "\n",
        "        if split=='train':\n",
        "            with open('/content/2018LA_Seg_Training Set/train.txt', 'r') as f:\n",
        "                self.image_list = f.readlines()\n",
        "        elif split == 'val':\n",
        "            with open('/content/2018LA_Seg_Training Set/val.txt', 'r') as f:\n",
        "                self.image_list = f.readlines()\n",
        "        elif split == 'test':\n",
        "            with open('/content/2018LA_Seg_Training Set/test.txt', 'r') as f:\n",
        "                self.image_list = f.readlines()\n",
        "        self.image_list = [item.replace('\\n','') for item in self.image_list]# [:4]\n",
        "\n",
        "        if num is not None:\n",
        "\n",
        "            self.image_list = self.image_list[:num]\n",
        "        print(\"total {} samples\".format(len(self.image_list)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_list[idx]\n",
        "\n",
        "        h5f = h5py.File(self._base_dir+\"/\"+image_name+\"/mri_norm2.h5\", 'r')\n",
        "        image = h5f['image'][:]\n",
        "        label = h5f['label'][:]\n",
        "\n",
        "        sample = {'image': image, 'label': label}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "class CenterCrop(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "\n",
        "        # pad the sample if necessary\n",
        "        if label.shape[0] <= self.output_size[0] or label.shape[1] <= self.output_size[1] or label.shape[2] <= \\\n",
        "                self.output_size[2]:\n",
        "            pw = max((self.output_size[0] - label.shape[0]) // 2 + 3, 0)\n",
        "            ph = max((self.output_size[1] - label.shape[1]) // 2 + 3, 0)\n",
        "            pd = max((self.output_size[2] - label.shape[2]) // 2 + 3, 0)\n",
        "            image = np.pad(image, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "            label = np.pad(label, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "\n",
        "        (w, h, d) = image.shape\n",
        "\n",
        "        w1 = int(round((w - self.output_size[0]) / 2.))\n",
        "        h1 = int(round((h - self.output_size[1]) / 2.))\n",
        "        d1 = int(round((d - self.output_size[2]) / 2.))\n",
        "\n",
        "        label = label[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "        image = image[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class ROICrop(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        tempL = np.nonzero(label)\n",
        "        minx, maxx = np.min(tempL[0]), np.max(tempL[0])\n",
        "        miny, maxy = np.min(tempL[1]), np.max(tempL[1])\n",
        "        minz, maxz = np.min(tempL[2]), np.max(tempL[2])\n",
        "        # get the center point\n",
        "        px = (maxx - minx) // 2 + minx\n",
        "        py = (maxy - miny) // 2 + miny\n",
        "        pz = (maxz - minz) // 2 + minz\n",
        "        w, h, d = label.shape\n",
        "        minx_out = px - self.output_size[0] // 2\n",
        "        maxx_out = px + self.output_size[0] // 2\n",
        "        miny_out = py - self.output_size[1] // 2\n",
        "        maxy_out = py + self.output_size[1] // 2\n",
        "        minz_out = pz - self.output_size[2] // 2\n",
        "        maxz_out = pz + self.output_size[2] // 2\n",
        "\n",
        "        if minx_out < 0:\n",
        "            minx_out = 0\n",
        "            maxx_out = minx_out + self.output_size[0]\n",
        "        if maxx_out > d:\n",
        "            maxx_out = d\n",
        "            minx_out = maxx_out - self.output_size[0]\n",
        "        if miny_out < 0:\n",
        "            miny_out = 0\n",
        "            maxy_out = miny_out + self.output_size[1]\n",
        "        if maxy_out > d:\n",
        "            maxy_out = d\n",
        "            miny_out = maxy_out - self.output_size[1]\n",
        "        if minz_out < 0:\n",
        "            minz_out = 0\n",
        "            maxz_out = minz_out + self.output_size[2]\n",
        "        if maxz_out > d:\n",
        "            maxz_out = d\n",
        "            minz_out = maxz_out - self.output_size[2]\n",
        "\n",
        "        label = label[minx_out:maxx_out, miny_out:maxy_out, minz_out:maxz_out]\n",
        "        image = image[minx_out:maxx_out, miny_out:maxy_out, minz_out:maxz_out]\n",
        "\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class RandomScale(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "\n",
        "        # pad the sample if necessary\n",
        "        if label.shape[0] <= self.output_size[0] or label.shape[1] <= self.output_size[1] or label.shape[2] <= \\\n",
        "                self.output_size[2]:\n",
        "            pw = max((self.output_size[0] - label.shape[0]) // 2 + 3, 0)\n",
        "            ph = max((self.output_size[1] - label.shape[1]) // 2 + 3, 0)\n",
        "            pd = max((self.output_size[2] - label.shape[2]) // 2 + 3, 0)\n",
        "            image = np.pad(image, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "            label = np.pad(label, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "\n",
        "        (w, h, d) = image.shape\n",
        "\n",
        "        w1 = int(round((w - self.output_size[0]) / 2.))\n",
        "        h1 = int(round((h - self.output_size[1]) / 2.))\n",
        "        d1 = int(round((d - self.output_size[2]) / 2.))\n",
        "\n",
        "        label = label[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "        image = image[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class RandomGammaCorrection(object):\n",
        "    # code source:\n",
        "    # Chen et al. Multi-task learning for left atrial segmentation on GE-MRI\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        # support n-d data\n",
        "        # :param img:\n",
        "        # :param mask:\n",
        "        # :return:\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if random.random() < 0.5:\n",
        "            gamma = random.random() * 1.2 + 0.8  # 0.8-2.0\n",
        "            print ('gamma: %f', gamma)\n",
        "            image = image ** (1 / gamma)\n",
        "            return {'image': image, 'label': label}\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"\n",
        "    Crop randomly the image in a sample\n",
        "    Args:\n",
        "    output_size (int): Desired output size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "\n",
        "        # pad the sample if necessary\n",
        "        if label.shape[0] <= self.output_size[0] or label.shape[1] <= self.output_size[1] or label.shape[2] <= \\\n",
        "                self.output_size[2]:\n",
        "            pw = max((self.output_size[0] - label.shape[0]) // 2 + 3, 0)\n",
        "            ph = max((self.output_size[1] - label.shape[1]) // 2 + 3, 0)\n",
        "            pd = max((self.output_size[2] - label.shape[2]) // 2 + 3, 0)\n",
        "            image = np.pad(image, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "            label = np.pad(label, [(pw, pw), (ph, ph), (pd, pd)], mode='constant', constant_values=0)\n",
        "\n",
        "        (w, h, d) = image.shape\n",
        "        w1 = np.random.randint(0, w - self.output_size[0])\n",
        "        h1 = np.random.randint(0, h - self.output_size[1])\n",
        "        d1 = np.random.randint(0, d - self.output_size[2])\n",
        "\n",
        "        label = label[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "        image = image[w1:w1 + self.output_size[0], h1:h1 + self.output_size[1], d1:d1 + self.output_size[2]]\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "class RandomRotFlip(object):\n",
        "    \"\"\"\n",
        "    Crop randomly flip the dataset in a sample\n",
        "    Args:\n",
        "    output_size (int): Desired output size\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        k = np.random.randint(0, 4)\n",
        "        axis_rt=(0,1)\n",
        "        axis_fp = np.random.randint(0, 1)\n",
        "        image = np.rot90(image, k, axes=axis_rt)\n",
        "        label = np.rot90(label, k, axes=axis_rt)\n",
        "\n",
        "        image = np.flip(image, axis=axis_fp).copy()\n",
        "        label = np.flip(label, axis=axis_fp).copy()\n",
        "\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class RandomFlip(object):\n",
        "    \"\"\"\n",
        "    Crop randomly flip the dataset in a sample\n",
        "    0 for flipup\n",
        "    1 for fliplr\n",
        "    Args:\n",
        "    output_size (int): Desired output size\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        axis = np.random.randint(1, 2)# for lasqs22\n",
        "        image = np.flip(image, axis=axis).copy()\n",
        "        label = np.flip(label, axis=axis).copy()\n",
        "\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "class RandomRotation(object):\n",
        "    \"\"\"\n",
        "       Rotate the dataset in a sample\n",
        "       Args:\n",
        "       output_size (int): rotated data\n",
        "       \"\"\"\n",
        "    def __init__(self, degrees):\n",
        "        self.degrees = degrees\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        k = np.random.randint(0, self.degrees)\n",
        "        image = rotate(image, angle=k, axes=(0, 1), reshape=False, order=1)\n",
        "        label = rotate(label, angle=k, axes=(0, 1), reshape=False, order=0)\n",
        "        return {'image': image, 'label': label}\n",
        "class RandomNoise(object):\n",
        "    def __init__(self, mu=0, sigma=0.1):\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        noise = np.clip(self.sigma * np.random.randn(image.shape[0], image.shape[1], image.shape[2]), -2*self.sigma, 2*self.sigma)\n",
        "        noise = noise + self.mu\n",
        "        image = image + noise\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "class CreateOnehotLabel(object):\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        onehot_label = np.zeros((self.num_classes, label.shape[0], label.shape[1], label.shape[2]), dtype=np.float32)\n",
        "        for i in range(self.num_classes):\n",
        "            onehot_label[i, :, :, :] = (label == i).astype(np.float32)\n",
        "        return {'image': image, 'label': label,'onehot_label':onehot_label}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2]).astype(np.float32)\n",
        "        if 'onehot_label' in sample:\n",
        "            return {'image': torch.from_numpy(image), 'label': torch.from_numpy(sample['label']).long(),\n",
        "                    'onehot_label': torch.from_numpy(sample['onehot_label']).long()}\n",
        "        else:\n",
        "            return {'image': torch.from_numpy(image), 'label': torch.from_numpy(sample['label']).long()}\n",
        "\n",
        "\n",
        "class TwoStreamBatchSampler(Sampler):\n",
        "    \"\"\"Iterate two sets of indices\n",
        "\n",
        "    An 'epoch' is one iteration through the primary indices.\n",
        "    During the epoch, the secondary indices are iterated through\n",
        "    as many times as needed.\n",
        "    \"\"\"\n",
        "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
        "        self.primary_indices = primary_indices\n",
        "        self.secondary_indices = secondary_indices\n",
        "        self.secondary_batch_size = secondary_batch_size\n",
        "        self.primary_batch_size = batch_size - secondary_batch_size\n",
        "\n",
        "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
        "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        primary_iter = iterate_once(self.primary_indices)\n",
        "        secondary_iter = iterate_eternally(self.secondary_indices)\n",
        "        return (\n",
        "            primary_batch + secondary_batch\n",
        "            for (primary_batch, secondary_batch)\n",
        "            in zip(grouper(primary_iter, self.primary_batch_size),\n",
        "                    grouper(secondary_iter, self.secondary_batch_size))\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.primary_indices) // self.primary_batch_size\n",
        "\n",
        "def iterate_once(iterable):\n",
        "    return np.random.permutation(iterable)\n",
        "\n",
        "\n",
        "def iterate_eternally(indices):\n",
        "    def infinite_shuffles():\n",
        "        while True:\n",
        "            yield np.random.permutation(indices)\n",
        "    return itertools.chain.from_iterable(infinite_shuffles())\n",
        "\n",
        "\n",
        "def grouper(iterable, n):\n",
        "    \"Collect data into fixed-length chunks or blocks\"\n",
        "    # grouper('ABCDEFG', 3) --> ABC DEF\"\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip(*args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from scipy.ndimage import distance_transform_edt as distance\n",
        "from skimage import segmentation as skimage_seg\n",
        "\n",
        "\n",
        "def dice_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target * target)\n",
        "    z_sum = torch.sum(score * score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "def dice_loss1(score, target):\n",
        "    # non-square\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target)\n",
        "    z_sum = torch.sum(score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "def iou_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    tp_sum = torch.sum(score * target)\n",
        "    fp_sum = torch.sum(score * (1-target))\n",
        "    fn_sum = torch.sum((1-score) * target)\n",
        "    loss = (tp_sum + smooth) / (tp_sum + fp_sum + fn_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "def entropy_loss(p,C=2):\n",
        "    ## p N*C*W*H*D\n",
        "    y1 = -1*torch.sum(p*torch.log(p+1e-6), dim=1)/torch.tensor(np.log(C)).cuda()\n",
        "    ent = torch.mean(y1)\n",
        "\n",
        "    return ent\n",
        "\n",
        "def softmax_dice_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
        "\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_softmax = F.softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "    n = input_logits.shape[1]\n",
        "    dice = 0\n",
        "    for i in range(0, n):\n",
        "        dice += dice_loss1(input_softmax[:, i], target_softmax[:, i])\n",
        "    mean_dice = dice / n\n",
        "\n",
        "    return mean_dice\n",
        "\n",
        "\n",
        "def entropy_loss_map(p, C=2):\n",
        "    ent = -1*torch.sum(p * torch.log(p + 1e-6), dim=1, keepdim=True)/torch.tensor(np.log(C)).cuda()\n",
        "    return ent\n",
        "\n",
        "def softmax_mse_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
        "\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_softmax = F.softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "\n",
        "    mse_loss = (input_softmax-target_softmax)**2\n",
        "    return mse_loss\n",
        "\n",
        "def softmax_kl_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns KL divergence\n",
        "\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_log_softmax = F.log_softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "\n",
        "    kl_div = F.kl_div(input_log_softmax, target_softmax, reduction='none')\n",
        "    return kl_div\n",
        "\n",
        "def symmetric_mse_loss(input1, input2):\n",
        "    \"\"\"Like F.mse_loss but sends gradients to both directions\n",
        "\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to both input1 and input2.\n",
        "    \"\"\"\n",
        "    assert input1.size() == input2.size()\n",
        "    return torch.mean((input1 - input2)**2)\n",
        "\n",
        "def scc_loss(cos_sim,tau,lb_center_12_bg,lb_center_12_la, un_center_12_bg, un_center_12_la):\n",
        "    loss_intra_bg = torch.exp((cos_sim(lb_center_12_bg, un_center_12_bg))/tau)\n",
        "    loss_intra_la = torch.exp((cos_sim(lb_center_12_la, un_center_12_la))/tau)\n",
        "    loss_inter_bg_la = torch.exp((cos_sim(lb_center_12_bg, un_center_12_la))/tau)\n",
        "    loss_inter_la_bg = torch.exp((cos_sim(lb_center_12_la, un_center_12_bg))/tau)\n",
        "    loss_contrast_bg = -torch.log(loss_intra_bg)+torch.log(loss_inter_bg_la)\n",
        "    loss_contrast_la = -torch.log(loss_intra_la)+torch.log(loss_inter_la_bg)\n",
        "    loss_contrast = torch.mean(loss_contrast_bg+loss_contrast_la)\n",
        "    return loss_contrast\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_sdf01(segmentation):\n",
        "    \"\"\"\n",
        "    compute the signed distance map of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "    if len(segmentation.shape) == 4: # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]): # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]): # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            negmask = ~posmask\n",
        "            posdis = distance(posmask)\n",
        "            negdis = distance(negmask)\n",
        "            boundary = skimage_seg.find_boundaries(posmask, mode='inner').astype(np.uint8)\n",
        "            sdf = negdis/np.max(negdis)/2 - posdis/np.max(posdis)/2 + 0.5\n",
        "            sdf[boundary>0] = 0.5\n",
        "            normalized_sdf[b][c] = sdf\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def compute_sdf1_1(segmentation):\n",
        "    \"\"\"\n",
        "    compute the signed distance map of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "    if len(segmentation.shape) == 4: # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]): # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]): # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            negmask = ~posmask\n",
        "            posdis = distance(posmask)\n",
        "            negdis = distance(negmask)\n",
        "            boundary = skimage_seg.find_boundaries(posmask, mode='inner').astype(np.uint8)\n",
        "            sdf = negdis/np.max(negdis) - posdis/np.max(posdis)\n",
        "            sdf[boundary>0] = 0\n",
        "            normalized_sdf[b][c] = sdf\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def compute_fore_dist(segmentation):\n",
        "    \"\"\"\n",
        "    compute the foreground of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "    if len(segmentation.shape) == 4: # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]): # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]): # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            posdis = distance(posmask)\n",
        "            normalized_sdf[b][c] = posdis/np.max(posdis)\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def sum_tensor(inp, axes, keepdim=False):\n",
        "    axes = np.unique(axes).astype(int)\n",
        "    if keepdim:\n",
        "        for ax in axes:\n",
        "            inp = inp.sum(int(ax), keepdim=True)\n",
        "    else:\n",
        "        for ax in sorted(axes, reverse=True):\n",
        "            inp = inp.sum(int(ax))\n",
        "    return inp\n",
        "\n",
        "\n",
        "def AAAI_sdf_loss(net_output, gt):\n",
        "    \"\"\"\n",
        "    net_output: net logits; shape=(batch_size, class, x, y, z)\n",
        "    gt: ground truth; (shape (batch_size, 1, x, y, z) OR (batch_size, x, y, z))\n",
        "    \"\"\"\n",
        "    smooth = 1e-5\n",
        "    axes = tuple(range(2, len(net_output.size())))\n",
        "    shp_x = net_output.shape\n",
        "    shp_y = gt.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if len(shp_x) != len(shp_y):\n",
        "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
        "\n",
        "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
        "            # if this is the case then gt is probably already a one hot encoding\n",
        "            y_onehot = gt\n",
        "        else:\n",
        "            gt = gt.long()\n",
        "            y_onehot = torch.zeros(shp_x)\n",
        "            if net_output.device.type == \"cuda\":\n",
        "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
        "            y_onehot.scatter_(1, gt, 1)\n",
        "        gt_sdm_npy = compute_sdf1_1(y_onehot.cpu().numpy())\n",
        "        gt_sdm = torch.from_numpy(gt_sdm_npy).float().cuda(net_output.device.index)\n",
        "    intersect = sum_tensor(net_output * gt_sdm, axes, keepdim=False)\n",
        "    pd_sum = sum_tensor(net_output ** 2, axes, keepdim=False)\n",
        "    gt_sum = sum_tensor(gt_sdm ** 2, axes, keepdim=False)\n",
        "    L_product = (intersect + smooth) / (intersect + pd_sum + gt_sum)\n",
        "    L_SDF_AAAI = - L_product.mean() + torch.norm(net_output - gt_sdm, 1)/torch.numel(net_output)\n",
        "\n",
        "    return L_SDF_AAAI\n",
        "\n",
        "\n",
        "def sdf_kl_loss(net_output, gt):\n",
        "    \"\"\"\n",
        "    net_output: net logits; shape=(batch_size, class, x, y, z)\n",
        "    gt: ground truth; (shape (batch_size, 1, x, y, z) OR (batch_size, x, y, z))\n",
        "    \"\"\"\n",
        "    smooth = 1e-5\n",
        "    axes = tuple(range(2, len(net_output.size())))\n",
        "    shp_x = net_output.shape\n",
        "    shp_y = gt.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if len(shp_x) != len(shp_y):\n",
        "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
        "\n",
        "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
        "            # if this is the case then gt is probably already a one hot encoding\n",
        "            y_onehot = gt\n",
        "        else:\n",
        "            gt = gt.long()\n",
        "            y_onehot = torch.zeros(shp_x)\n",
        "            if net_output.device.type == \"cuda\":\n",
        "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
        "            y_onehot.scatter_(1, gt, 1)\n",
        "        gt_sdf_npy = compute_sdf(y_onehot.cpu().numpy())\n",
        "        gt_sdf = torch.from_numpy(gt_sdf_npy+smooth).float().cuda(net_output.device.index)\n",
        "    sdf_kl_loss = F.kl_div(net_output, gt_sdf[:,1:2,...], reduction='batchmean')\n",
        "\n",
        "    return sdf_kl_loss\n",
        "\n",
        "def weighted_ce_loss(net_output, gt):\n",
        "    n_dims = gt.shape[-1]\n",
        "    soft_pred = F.softmax(net_output)\n",
        "    loss = 0.\n",
        "    for i in range(n_dims):\n",
        "        gti = gt[:,i,:,:,:]\n",
        "        predi = soft_pred[:,i,:,:,:]\n",
        "        weighted = 1-(torch.sum(gti)/torch.sum(gt))\n",
        "        loss = loss -torch.mean(weighted*gti*torch.log(torch.clip_by_value(predi, 0.005, 1)))\n",
        "    return loss\n",
        "\n",
        "def focal_loss(net_output, gt):\n",
        "    n_dims = net_output.shape[1]\n",
        "\n",
        "    soft_pred = F.softmax(net_output)\n",
        "    gt = F.one_hot(gt)\n",
        "    loss = 0.\n",
        "    for i in range(n_dims):\n",
        "        gti = gt[:,:,:,:,i]\n",
        "        predi = soft_pred[:,i,:,:,:]\n",
        "        focal_loss=torch.pow( (1-predi), 4, name=None)\n",
        "        loss = loss -torch.mean(focal_loss*gti*torch.log(predi))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Ly3h2b7m1e2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid_rampup(current, rampup_length):\n",
        "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
        "    if rampup_length == 0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        current = np.clip(current, 0.0, rampup_length)\n",
        "        phase = 1.0 - current / rampup_length\n",
        "        return float(np.exp(-5.0 * phase * phase))\n",
        "\n",
        "\n",
        "def linear_rampup(current, rampup_length):\n",
        "    \"\"\"Linear rampup\"\"\"\n",
        "    assert current >= 0 and rampup_length >= 0\n",
        "    if current >= rampup_length:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return current / rampup_length\n",
        "\n",
        "\n",
        "def cosine_rampdown(current, rampdown_length):\n",
        "    \"\"\"Cosine rampdown from https://arxiv.org/abs/1608.03983\"\"\"\n",
        "    assert 0 <= current <= rampdown_length\n",
        "    return float(.5 * (np.cos(np.pi * current / rampdown_length) + 1))"
      ],
      "metadata": {
        "id": "0BoOZDkR1e4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from glob import glob\n",
        "\n",
        "import h5py\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from medpy import metric\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def test_single_case(net, image, stride_xy, stride_z, patch_size, num_classes=1):\n",
        "    w, h, d = image.shape\n",
        "\n",
        "    # if the size of image is less than patch_size, then padding it\n",
        "    add_pad = False\n",
        "    if w < patch_size[0]:\n",
        "        w_pad = patch_size[0]-w\n",
        "        add_pad = True\n",
        "    else:\n",
        "        w_pad = 0\n",
        "    if h < patch_size[1]:\n",
        "        h_pad = patch_size[1]-h\n",
        "        add_pad = True\n",
        "    else:\n",
        "        h_pad = 0\n",
        "    if d < patch_size[2]:\n",
        "        d_pad = patch_size[2]-d\n",
        "        add_pad = True\n",
        "    else:\n",
        "        d_pad = 0\n",
        "    wl_pad, wr_pad = w_pad//2, w_pad-w_pad//2\n",
        "    hl_pad, hr_pad = h_pad//2, h_pad-h_pad//2\n",
        "    dl_pad, dr_pad = d_pad//2, d_pad-d_pad//2\n",
        "    if add_pad:\n",
        "        image = np.pad(image, [(wl_pad, wr_pad), (hl_pad, hr_pad),\n",
        "                               (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
        "    ww, hh, dd = image.shape\n",
        "\n",
        "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
        "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
        "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
        "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
        "    cnt = np.zeros(image.shape).astype(np.float32)\n",
        "\n",
        "    for x in range(0, sx):\n",
        "        xs = min(stride_xy*x, ww-patch_size[0])\n",
        "        for y in range(0, sy):\n",
        "            ys = min(stride_xy * y, hh-patch_size[1])\n",
        "            for z in range(0, sz):\n",
        "                zs = min(stride_z * z, dd-patch_size[2])\n",
        "                test_patch = image[xs:xs+patch_size[0],\n",
        "                                   ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
        "                test_patch = np.expand_dims(np.expand_dims(\n",
        "                    test_patch, axis=0), axis=0).astype(np.float32)\n",
        "                test_patch = torch.from_numpy(test_patch).cuda()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    y1 = net(test_patch)\n",
        "                    # ensemble\n",
        "                    if isinstance(y1, list):\n",
        "                        y1 = y1[0]\n",
        "                    y = torch.softmax(y1, dim=1)\n",
        "                y = y.cpu().data.numpy()\n",
        "                y = y[0, :, :, :, :]\n",
        "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
        "                    = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y\n",
        "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
        "                    = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1\n",
        "    score_map = score_map/np.expand_dims(cnt, axis=0)\n",
        "    label_map = np.argmax(score_map, axis=0)\n",
        "\n",
        "    if add_pad:\n",
        "        label_map = label_map[wl_pad:wl_pad+w,\n",
        "                              hl_pad:hl_pad+h, dl_pad:dl_pad+d]\n",
        "        score_map = score_map[:, wl_pad:wl_pad +\n",
        "                              w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]\n",
        "    return label_map\n",
        "\n",
        "\n",
        "def cal_metric(gt, pred):\n",
        "    if pred.sum() > 0 and gt.sum() > 0:\n",
        "        dice = metric.binary.dc(pred, gt)\n",
        "        hd95 = metric.binary.hd95(pred, gt)\n",
        "        asd = metric.binary.asd(pred, gt)\n",
        "        jaccard = metric.binary.jc(pred, gt)\n",
        "        return np.array([dice, hd95, jaccard, asd])\n",
        "    else:\n",
        "        return np.zeros(4)\n",
        "\n",
        "\n",
        "def test_all_case(net, base_dir, test_list=\"full_test.list\", num_classes=2, patch_size=(80, 80, 80), stride_xy=32, stride_z=24):\n",
        "    with open(base_dir + '/{}'.format(test_list), 'r') as f:\n",
        "        image_list = f.readlines()\n",
        "    image_list = [base_dir + \"/{}/mri_norm2.h5\".format(\n",
        "        item.replace('\\n', '').split(\",\")[0]) for item in image_list]\n",
        "    total_metric = np.zeros((num_classes-1, 4))\n",
        "    print(\"Validation begin\")\n",
        "    for image_path in tqdm(image_list):\n",
        "        h5f = h5py.File(image_path, 'r')\n",
        "        image = h5f['image'][:]\n",
        "        label = h5f['label'][:]\n",
        "        prediction = test_single_case(\n",
        "            net, image, stride_xy, stride_z, patch_size, num_classes=num_classes)\n",
        "        for i in range(1, num_classes):\n",
        "            total_metric[i-1, :] += cal_metric(label == i, prediction == i)\n",
        "    print(\"Validation end\")\n",
        "    return total_metric / len(image_list)"
      ],
      "metadata": {
        "id": "ifO9qJObL2YE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tensorboardX import SummaryWriter\n",
        "import shutil\n",
        "import argparse\n",
        "import logging\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.nn import CosineSimilarity\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "args = argparse.Namespace(\n",
        "    root_path='/content/2018LA_Seg_Training Set',\n",
        "    exp='/content/SCC',\n",
        "    model='SCC',\n",
        "    max_iterations=6000,\n",
        "    batch_size=4,\n",
        "    deterministic=1,\n",
        "    base_lr=0.01,\n",
        "    patch_size=[80, 112, 112],\n",
        "    seed=1337,\n",
        "    num_classes=2,\n",
        "    labeled_bs=2,\n",
        "    labelnum=6,\n",
        "    total_labeled_num=60,\n",
        "    ema_decay=0.99,\n",
        "    consistency_type=\"mse\",\n",
        "    consistency=0.1,\n",
        "    consistency_rampup=400.0,\n",
        "    has_triup=True,\n",
        "    my_lambda=1,\n",
        "    tau=1,\n",
        "    ramp_up_lambda=1,\n",
        "    rampup_param=40.0,\n",
        "    has_contrastive=1,\n",
        "    only_supervised=0\n",
        ")\n",
        "\n",
        "exp_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
        "\n",
        "train_data_path = args.root_path\n",
        "snapshot_path = \"/content/model{}_{}/{}\".format(\n",
        "        args.exp, args.labelnum, args.model)\n",
        "\n",
        "\n",
        "batch_size = args.batch_size\n",
        "max_iterations = args.max_iterations\n",
        "base_lr = args.base_lr\n",
        "labeled_bs = args.labeled_bs\n",
        "\n",
        "if not args.deterministic:\n",
        "    cudnn.benchmark = True #\n",
        "    cudnn.deterministic = False #\n",
        "else:\n",
        "    cudnn.benchmark = False  # True #\n",
        "    cudnn.deterministic = True  # False #\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "num_classes = args.num_classes\n",
        "patch_size = args.patch_size\n",
        "\n",
        "def get_current_consistency_weight(epoch):\n",
        "    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
        "    return args.ramp_up_lambda * sigmoid_rampup(epoch, args.rampup_param)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## make logger file\n",
        "    if not os.path.exists(snapshot_path):\n",
        "        os.makedirs(snapshot_path)\n",
        "\n",
        "    logging.basicConfig(filename=snapshot_path+\"/log.txt\", level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
        "    logging.info(str(args))\n",
        "\n",
        "    # Network definition\n",
        "    # E2DNet for segmentation\n",
        "    encoder = VNet_Encoder(n_channels=1, n_filters=16, normalization='batchnorm',has_dropout=True).cuda()\n",
        "    seg_decoder_1 = MainDecoder(n_classes=num_classes, n_filters=16, normalization='batchnorm',has_dropout=True).cuda()\n",
        "    if args.has_triup:\n",
        "        # adopted this decoder, the performance will hit dice=0.9056, 95hd=6.74\n",
        "        # triup+ramp_up, dice=0.9106, 95hd=6.01\n",
        "        seg_decoder_2 = TriupDecoder(n_classes=num_classes, n_filters=16, normalization='batchnorm',has_dropout=True).cuda()\n",
        "    else:\n",
        "        seg_decoder_2 = MainDecoder(n_classes=num_classes, n_filters=16, normalization='batchnorm',has_dropout=True).cuda()\n",
        "    seg_params = list(encoder.parameters())+list(seg_decoder_1.parameters())+list(seg_decoder_2.parameters())\n",
        "    encoder.train()\n",
        "    seg_decoder_1.train()\n",
        "    seg_decoder_2.train()\n",
        "    # classification model\n",
        "    cls_model = center_model(num_classes=num_classes,ndf=64)\n",
        "    cls_model.cuda()\n",
        "    db_train = LAHeart(base_dir=train_data_path,\n",
        "                       split='train', # train/val split\n",
        "                       # num=args.labelnum,#16,\n",
        "                       transform = transforms.Compose([\n",
        "                          RandomRotFlip(),\n",
        "                          RandomCrop(patch_size),\n",
        "                          ToTensor(),\n",
        "                          ]))\n",
        "\n",
        "    labelnum = args.labelnum    # default 16\n",
        "    label_idx = list(range(0,60))\n",
        "    random.shuffle(label_idx)\n",
        "    labeled_idxs = label_idx[:labelnum]\n",
        "    unlabeled_idxs = label_idx[labelnum:60]\n",
        "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, batch_size, batch_size-labeled_bs)\n",
        "    def worker_init_fn(worker_id):\n",
        "        random.seed(args.seed+worker_id)\n",
        "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True,worker_init_fn=worker_init_fn)\n",
        "\n",
        "    optimizer = optim.SGD(seg_params, lr=base_lr, momentum=0.9, weight_decay=0.0001)\n",
        "    cos_sim = CosineSimilarity(dim=1,eps=1e-6)\n",
        "\n",
        "    writer = SummaryWriter(snapshot_path+'/log')\n",
        "    logging.info(\"{} itertations per epoch\".format(len(trainloader)))\n",
        "\n",
        "    iter_num = 0\n",
        "    max_epoch = max_iterations//len(trainloader)+1\n",
        "    lr_ = base_lr\n",
        "\n",
        "    iterator = tqdm(range(max_epoch), ncols=70)\n",
        "    for epoch_num in iterator:\n",
        "        time1 = time.time()\n",
        "        for i_batch, sampled_batch in enumerate(trainloader):\n",
        "            time2 = time.time()\n",
        "            # print('fetch data cost {}'.format(time2-time1))\n",
        "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
        "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
        "\n",
        "            features = encoder(volume_batch)\n",
        "            outputs_1 = seg_decoder_1(features)\n",
        "            outputs_2 = seg_decoder_2(features)\n",
        "            outputs_soft_1 = F.softmax(outputs_1,dim=1)\n",
        "            outputs_soft_2 = F.softmax(outputs_2,dim=1)\n",
        "\n",
        "            '''\n",
        "            # fully supervised manner\n",
        "            loss_seg_1 = F.cross_entropy(outputs_1, label_batch)#ce_loss(outputs_1[:labeled_bs, 0, ...], label_batch[:labeled_bs].float())\n",
        "            loss_seg_dice_1 = losses.dice_loss(outputs_soft_1[:, 1, :, :, :], label_batch == 1)\n",
        "            loss_seg_2 = F.cross_entropy(outputs_2, label_batch)\n",
        "            loss_seg_dice_2 = losses.dice_loss(outputs_soft_2[:,1, :, :, :], label_batch == 1)\n",
        "            '''\n",
        "            ## calculate the supervised loss\n",
        "            loss_seg_1 = F.cross_entropy(outputs_1[:labeled_bs, ...], label_batch[:labeled_bs])#ce_loss(outputs_1[:labeled_bs, 0, ...], label_batch[:labeled_bs].float())\n",
        "            loss_seg_dice_1 = dice_loss(outputs_soft_1[:labeled_bs, 1, :, :, :], label_batch[:labeled_bs] == 1)\n",
        "            loss_seg_2 = F.cross_entropy(outputs_2[:labeled_bs, ...], label_batch[:labeled_bs])\n",
        "            loss_seg_dice_2 = dice_loss(outputs_soft_2[:labeled_bs,1, :, :, :], label_batch[:labeled_bs] == 1)\n",
        "\n",
        "            supervised_loss = 0.5*(loss_seg_dice_1 + loss_seg_dice_2) + 0.5*(loss_seg_1 + loss_seg_2)\n",
        "\n",
        "            if args.has_contrastive == 1:\n",
        "\n",
        "                create_center_1_bg = cls_model(outputs_1[:,0,...].unsqueeze(1))# 4,1,x,y,z->4,2\n",
        "                create_center_1_la = cls_model(outputs_1[:,1,...].unsqueeze(1))\n",
        "                create_center_2_bg = cls_model(outputs_2[:,0,...].unsqueeze(1))\n",
        "                create_center_2_la = cls_model(outputs_2[:,1,...].unsqueeze(1))\n",
        "\n",
        "                create_center_soft_1_bg = F.softmax(create_center_1_bg, dim=1)# dims(4,2)\n",
        "                create_center_soft_1_la = F.softmax(create_center_1_la, dim=1)\n",
        "                create_center_soft_2_bg = F.softmax(create_center_2_bg, dim=1)# dims(4,2)\n",
        "                create_center_soft_2_la = F.softmax(create_center_2_la, dim=1)\n",
        "\n",
        "                lb_center_12_bg = torch.cat((create_center_soft_1_bg[:labeled_bs,...], create_center_soft_2_bg[:labeled_bs,...]),dim=0)# 4,2\n",
        "                lb_center_12_la = torch.cat((create_center_soft_1_la[:labeled_bs,...], create_center_soft_2_la[:labeled_bs,...]),dim=0)\n",
        "                un_center_12_bg = torch.cat((create_center_soft_1_bg[labeled_bs:,...], create_center_soft_2_bg[labeled_bs:,...]),dim=0)\n",
        "                un_center_12_la = torch.cat((create_center_soft_1_la[labeled_bs:,...], create_center_soft_2_la[labeled_bs:,...]),dim=0)\n",
        "\n",
        "\n",
        "                # cosine similarity\n",
        "                loss_contrast = scc_loss(cos_sim, args.tau, lb_center_12_bg,lb_center_12_la, un_center_12_bg, un_center_12_la)\n",
        "                if args.ramp_up_lambda!=0:\n",
        "                    consistency_weight = get_current_consistency_weight(iter_num//150)\n",
        "                    loss = supervised_loss + consistency_weight*loss_contrast\n",
        "                else:\n",
        "                    loss = supervised_loss + args.my_lambda * loss_contrast\n",
        "\n",
        "            if args.only_supervised==1:\n",
        "                print('only supervised')\n",
        "                loss = supervised_loss\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            iter_num = iter_num + 1\n",
        "            writer.add_scalar('lr', lr_, iter_num)\n",
        "            writer.add_scalar('loss/loss', loss, iter_num)\n",
        "            writer.add_scalar('loss/loss_seg', loss_seg_1+loss_seg_2, iter_num)\n",
        "            writer.add_scalar('loss/loss_dice', loss_seg_dice_1+loss_seg_dice_2, iter_num)\n",
        "            writer.add_scalar('loss/loss_supervised', supervised_loss, iter_num)\n",
        "            if args.has_contrastive == 1:\n",
        "                writer.add_scalar('loss/loss_contrastive', loss_contrast, iter_num)\n",
        "\n",
        "\n",
        "\n",
        "            logging.info(\n",
        "                'iteration %d : loss : %f, loss_seg_1: %f, loss_seg_2: %f, loss_dice_1: %f, loss_dice_2: %f' %\n",
        "                (iter_num, loss.item(),   loss_seg_1.item(), loss_seg_2.item(), loss_seg_dice_1.item(), loss_seg_dice_2.item()))\n",
        "            if args.has_contrastive == 1:\n",
        "                logging.info(\n",
        "                'iteration %d : supervised loss : %f, contrastive loss: %f' %\n",
        "                (iter_num, supervised_loss.item(),  loss_contrast.item()))\n",
        "\n",
        "            if iter_num > 0 and iter_num % 200 == 0:\n",
        "                encoder.eval()\n",
        "                seg_decoder_1.eval()\n",
        "                seg_decoder_2.eval()\n",
        "\n",
        "                # Calculate average metrics on validation data\n",
        "                avg_metric1 = test_all_case(\n",
        "                    encoder,\n",
        "                    args.root_path,\n",
        "                    test_list=\"val.txt\",\n",
        "                    num_classes=args.num_classes,\n",
        "                    patch_size=args.patch_size,\n",
        "                    stride_xy=64,\n",
        "                    stride_z=64\n",
        "                )\n",
        "\n",
        "                # Save the best model based on Dice score\n",
        "                avg_dice_score = avg_metric1[:, 0].mean()  # Assuming the Dice score is in column 0\n",
        "                if avg_dice_score > best_performance:\n",
        "                   best_performance = avg_dice_score\n",
        "                   save_mode_path = os.path.join(\n",
        "                        snapshot_path,\n",
        "                        'model_encoder_iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4))\n",
        "                    )\n",
        "                   save_best = os.path.join(snapshot_path, '{}_best_model_encoder.pth'.format(args.model))\n",
        "\n",
        "                    # Save encoder and decoders separately\n",
        "                   torch.save({\n",
        "                        'encoder_state_dict': encoder.state_dict()\n",
        "                    }, save_mode_path)\n",
        "\n",
        "                   torch.save({\n",
        "                        'encoder_state_dict': encoder.state_dict()\n",
        "                    }, save_best)\n",
        "\n",
        "                # Log validation metrics to TensorBoard and console\n",
        "                writer.add_scalar('info/val_dice_score', avg_metric1[0, 0], iter_num)\n",
        "                writer.add_scalar('info/val_hd95', avg_metric1[0, 1], iter_num)\n",
        "                writer.add_scalar('info/val_asd', avg_metric1[0, 3], iter_num)\n",
        "                writer.add_scalar('info/val_jaccard', avg_metric1[0, 2], iter_num)\n",
        "\n",
        "                logging.info(\n",
        "                    'Validation at iteration %d : Dice Score: %f, HD95: %f, Jaccard: %f, ASD: %f' %\n",
        "                    (iter_num, avg_metric1[0, 0].mean(), avg_metric1[0, 1].mean(), avg_metric1[0, 2].mean(), avg_metric1[0, 3].mean())\n",
        "                )\n",
        "\n",
        "                # Calculate average metrics on validation data\n",
        "                avg_metric2 = test_all_case(\n",
        "                    seg_decoder_1,\n",
        "                    args.root_path,\n",
        "                    test_list=\"val.txt\",\n",
        "                    num_classes=args.num_classes,\n",
        "                    patch_size=args.patch_size,\n",
        "                    stride_xy=64,\n",
        "                    stride_z=64\n",
        "                )\n",
        "\n",
        "                # Save the best model based on Dice score\n",
        "                avg_dice_score = avg_metric2[:, 0].mean()  # Assuming the Dice score is in column 0\n",
        "                if avg_dice_score > best_performance:\n",
        "                   best_performance = avg_dice_score\n",
        "                   save_mode_path = os.path.join(\n",
        "                        snapshot_path,\n",
        "                        'model_decoder1_iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4))\n",
        "                    )\n",
        "                   save_best = os.path.join(snapshot_path, '{}_best_model_decoder1.pth'.format(args.model))\n",
        "                   torch.save({\n",
        "                        'seg_decoder_1_state_dict': seg_decoder_1.state_dict()\n",
        "                    }, save_mode_path)\n",
        "\n",
        "                   torch.save({\n",
        "                        'seg_decoder_1_state_dict': seg_decoder_1.state_dict()\n",
        "                    }, save_best)\n",
        "\n",
        "                # Log validation metrics to TensorBoard and console\n",
        "                writer.add_scalar('info/val_dice_score', avg_metric2[0, 0], iter_num)\n",
        "                writer.add_scalar('info/val_hd95', avg_metric2[0, 1], iter_num)\n",
        "                writer.add_scalar('info/val_asd', avg_metric2[0, 3], iter_num)\n",
        "                writer.add_scalar('info/val_jaccard', avg_metric2[0, 2], iter_num)\n",
        "\n",
        "                logging.info(\n",
        "                    'Validation at iteration %d : Dice Score: %f, HD95: %f, Jaccard: %f, ASD: %f' %\n",
        "                    (iter_num, avg_metric2[0, 0].mean(), avg_metric2[0, 1].mean(), avg_metric2[0, 2].mean(), avg_metric2[0, 3].mean())\n",
        "                )\n",
        "\n",
        "                # Calculate average metrics on validation data\n",
        "                avg_metric3 = test_all_case(\n",
        "                    seg_decoder_2,\n",
        "                    args.root_path,\n",
        "                    test_list=\"val.txt\",\n",
        "                    num_classes=args.num_classes,\n",
        "                    patch_size=args.patch_size,\n",
        "                    stride_xy=64,\n",
        "                    stride_z=64\n",
        "                )\n",
        "\n",
        "                # Save the best model based on Dice score\n",
        "                avg_dice_score = avg_metric3[:, 0].mean()  # Assuming the Dice score is in column 0\n",
        "                if avg_dice_score > best_performance:\n",
        "                   best_performance = avg_dice_score\n",
        "                   save_mode_path = os.path.join(\n",
        "                        snapshot_path,\n",
        "                        'model_decoder2_iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4))\n",
        "                    )\n",
        "                   save_best = os.path.join(snapshot_path, '{}_best_model_decoder2.pth'.format(args.model))\n",
        "\n",
        "                    # Save encoder and decoders separately\n",
        "                   torch.save({\n",
        "                        'seg_decoder_2_state_dict': seg_decoder_2.state_dict(),\n",
        "                    }, save_mode_path)\n",
        "\n",
        "                   torch.save({\n",
        "                        'seg_decoder_2_state_dict': seg_decoder_2.state_dict(),\n",
        "                    }, save_best)\n",
        "\n",
        "                # Log validation metrics to TensorBoard and console\n",
        "                writer.add_scalar('info/val_dice_score', avg_metric3[0, 0], iter_num)\n",
        "                writer.add_scalar('info/val_hd95', avg_metric3[0, 1], iter_num)\n",
        "                writer.add_scalar('info/val_asd', avg_metric3[0, 3], iter_num)\n",
        "                writer.add_scalar('info/val_jaccard', avg_metric3[0, 2], iter_num)\n",
        "\n",
        "                logging.info(\n",
        "                    'Validation at iteration %d : Dice Score: %f, HD95: %f, Jaccard: %f, ASD: %f' %\n",
        "                    (iter_num, avg_metric3[0, 0].mean(), avg_metric3[0, 1].mean(), avg_metric3[0, 2].mean(), avg_metric3[0, 3].mean())\n",
        "                )\n",
        "\n",
        "                # Switch back to training mode\n",
        "                encoder.train()\n",
        "                seg_decoder_1.train()\n",
        "                seg_decoder_2.train()\n",
        "\n",
        "            if iter_num % 2500 == 0:\n",
        "                lr_ = base_lr * 0.1 ** (iter_num // 2500)\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_\n",
        "            ## save checkpoint\n",
        "            if iter_num % 200 == 0:\n",
        "                save_mode_path = os.path.join(snapshot_path, 'iter_' + str(iter_num) + '.pth')\n",
        "                torch.save({'encoder_state_dict':encoder.state_dict(),\n",
        "                            'seg_decoder_1_state_dict': seg_decoder_1.state_dict(),\n",
        "                            'seg_decoder_2_state_dict': seg_decoder_2.state_dict()}, save_mode_path)\n",
        "                logging.info(\"save model to {}\".format(save_mode_path))\n",
        "\n",
        "            if iter_num >= max_iterations:\n",
        "                break\n",
        "            time1 = time.time()\n",
        "        if iter_num >= max_iterations:\n",
        "            iterator.close()\n",
        "            break\n",
        "    writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX4A58Ll1e62",
        "outputId": "859b0268-4e5b-4214-f583-2cb561025369",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 60 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1999/2001 [1:42:56<00:06,  3.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "ENCODE_NEIGHBOURHOOD_3D_KERNEL = np.array([[[128, 64], [32, 16]], [[8, 4],\n",
        "                                                                   [2, 1]]])\n",
        "\n",
        "# _NEIGHBOUR_CODE_TO_NORMALS is a lookup table.\n",
        "# For every binary neighbour code\n",
        "# (2x2x2 neighbourhood = 8 neighbours = 8 bits = 256 codes)\n",
        "# it contains the surface normals of the triangles (called \"surfel\" for\n",
        "# \"surface element\" in the following). The length of the normal\n",
        "# vector encodes the surfel area.\n",
        "#\n",
        "# created using the marching_cube algorithm\n",
        "# see e.g. https://en.wikipedia.org/wiki/Marching_cubes\n",
        "# pylint: disable=line-too-long\n",
        "_NEIGHBOUR_CODE_TO_NORMALS = [\n",
        "    [[0, 0, 0]],\n",
        "    [[0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n",
        "    [[0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25], [-0.125, 0.125, -0.125]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[0.5, 0.0, 0.0], [0.5, 0.0, 0.0]],\n",
        "    [[0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.5, 0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, 0.0, -0.5], [0.25, 0.25, 0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.375, 0.375, 0.375], [0.0, -0.25, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[0.125, -0.125, -0.125], [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.375, 0.375, 0.375], [0.0, 0.25, -0.25], [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25], [0.125, 0.125, 0.125]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25]],\n",
        "    [[0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n",
        "    [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125], [0.25, 0.25, -0.25]],\n",
        "    [[0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[-0.375, -0.375, 0.375], [-0.0, 0.25, 0.25], [0.125, 0.125, -0.125], [-0.25, -0.0, -0.25]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.25, 0.25, -0.25], [0.25, 0.25, -0.25], [0.125, 0.125, -0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25], [-0.125, 0.125, -0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.25, -0.25], [0.375, -0.375, -0.375], [-0.125, 0.125, 0.125], [0.25, 0.25, 0.0]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n",
        "    [[0.0, 0.5, 0.0], [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, 0.5, 0.0], [0.125, -0.125, 0.125], [-0.25, 0.25, -0.25]],\n",
        "    [[0.0, 0.5, 0.0], [0.0, -0.5, 0.0]],\n",
        "    [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0], [0.125, -0.125, 0.125]],\n",
        "    [[-0.375, -0.375, -0.375], [-0.25, 0.0, 0.25], [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n",
        "    [[0.125, 0.125, 0.125], [0.0, -0.5, 0.0], [-0.25, -0.25, -0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.5, 0.0], [-0.25, -0.25, -0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n",
        "    [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.375, 0.375, -0.375], [-0.25, -0.25, 0.0], [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n",
        "    [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0], [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n",
        "    [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n",
        "    [[-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25]],\n",
        "    [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.375, -0.375, 0.375], [0.0, -0.25, -0.25], [-0.125, 0.125, -0.125], [0.25, 0.25, 0.0]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.25, -0.25], [-0.25, 0.25, -0.25], [-0.125, 0.125, -0.125], [-0.125, 0.125, -0.125]],\n",
        "    [[-0.25, 0.0, -0.25], [0.375, -0.375, -0.375], [0.0, 0.25, -0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n",
        "    [[-0.25, -0.0, -0.25], [-0.375, 0.375, 0.375], [-0.25, -0.25, 0.0], [-0.125, 0.125, 0.125]],\n",
        "    [[0.0, 0.0, -0.5], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [0.0, 0.0, 0.5]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125], [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[0.125, 0.125, 0.125], [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n",
        "    [[0.125, -0.125, 0.125], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.25, 0.0, 0.25], [-0.375, -0.375, 0.375], [-0.25, 0.25, 0.0], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n",
        "    [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n",
        "    [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, -0.25, -0.25], [0.125, -0.125, -0.125]],\n",
        "    [[-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.375, -0.375, 0.375], [0.0, 0.25, 0.25], [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n",
        "    [[0.0, -0.5, 0.0], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.375, -0.375, 0.375], [0.25, -0.25, 0.0], [0.0, 0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[0.125, 0.125, 0.125], [0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n",
        "    [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n",
        "    [[0.125, 0.125, 0.125], [0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n",
        "    [[-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[-0.375, -0.375, 0.375], [0.25, -0.25, 0.0], [0.0, 0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.5, 0.0], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[0.375, -0.375, 0.375], [0.0, 0.25, 0.25], [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n",
        "    [[-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125], [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, -0.25, -0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.25, 0.25], [0.0, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25], [0.0, 0.25, 0.25], [0.0, 0.25, 0.25]],\n",
        "    [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.125, 0.125, 0.125], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.25, 0.0, 0.25], [-0.375, -0.375, 0.375], [-0.25, 0.25, 0.0], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25], [0.25, 0.0, 0.25]],\n",
        "    [[-0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, 0.125, 0.125], [0.25, 0.25, 0.25], [0.0, 0.0, 0.5]],\n",
        "    [[-0.0, 0.0, 0.5], [0.0, 0.0, 0.5]],\n",
        "    [[0.0, 0.0, -0.5], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.0, -0.25], [-0.375, 0.375, 0.375], [-0.25, -0.25, 0.0], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [0.25, 0.0, -0.25]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.0, -0.25], [0.375, -0.375, -0.375], [0.0, 0.25, -0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.25, 0.25, -0.25], [-0.25, 0.25, -0.25], [-0.125, 0.125, -0.125], [-0.125, 0.125, -0.125]],\n",
        "    [[-0.0, 0.5, 0.0], [-0.25, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[0.375, -0.375, 0.375], [0.0, -0.25, -0.25], [-0.125, 0.125, -0.125], [0.25, 0.25, 0.0]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.0, 0.5], [0.25, -0.25, 0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, -0.25, 0.25]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n",
        "    [[-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n",
        "    [[0.125, 0.125, 0.125], [-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0]],\n",
        "    [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0], [-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n",
        "    [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.375, 0.375, -0.375], [-0.25, -0.25, 0.0], [-0.125, 0.125, -0.125], [-0.25, 0.0, 0.25]],\n",
        "    [[0.0, 0.5, 0.0], [0.25, 0.25, -0.25], [-0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n",
        "    [[0.0, -0.5, 0.0], [-0.25, -0.25, -0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.0, -0.5, 0.0], [-0.25, -0.25, -0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[-0.375, -0.375, -0.375], [-0.25, 0.0, 0.25], [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n",
        "    [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.5, 0.0], [0.0, -0.5, 0.0]],\n",
        "    [[0.0, 0.5, 0.0], [0.125, -0.125, 0.125], [-0.25, 0.25, -0.25]],\n",
        "    [[0.0, 0.5, 0.0], [-0.25, 0.25, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.25, -0.25, 0.0], [-0.25, 0.25, 0.0]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.0, 0.25, -0.25], [0.375, -0.375, -0.375], [-0.125, 0.125, 0.125], [0.25, 0.25, 0.0]],\n",
        "    [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25], [-0.125, 0.125, -0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.25, 0.25, -0.25], [0.25, 0.25, -0.25], [0.125, 0.125, -0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.0, 0.0, 0.5], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[-0.375, -0.375, 0.375], [-0.0, 0.25, 0.25], [0.125, 0.125, -0.125], [-0.25, -0.0, -0.25]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.125, -0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.0, -0.5, 0.0], [0.125, 0.125, -0.125], [0.25, 0.25, -0.25]],\n",
        "    [[0.0, -0.25, 0.25], [0.0, 0.25, -0.25]],\n",
        "    [[0.125, 0.125, 0.125], [0.125, -0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.375, 0.375, 0.375], [0.0, 0.25, -0.25], [-0.125, -0.125, -0.125], [-0.25, 0.25, 0.0]],\n",
        "    [[0.125, -0.125, -0.125], [0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.125, 0.125, 0.125], [0.375, 0.375, 0.375], [0.0, -0.25, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[-0.125, -0.125, -0.125], [-0.25, -0.25, -0.25], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, 0.0, -0.5], [0.25, 0.25, 0.25], [-0.125, -0.125, -0.125]],\n",
        "    [[0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.5, 0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[-0.125, -0.125, 0.125], [0.125, -0.125, -0.125]],\n",
        "    [[0.0, -0.25, -0.25], [0.0, 0.25, 0.25]],\n",
        "    [[0.125, -0.125, -0.125]],\n",
        "    [[0.5, 0.0, 0.0], [0.5, 0.0, 0.0]],\n",
        "    [[-0.5, 0.0, 0.0], [-0.25, 0.25, 0.25], [-0.125, 0.125, 0.125]],\n",
        "    [[0.5, 0.0, 0.0], [0.25, -0.25, 0.25], [-0.125, 0.125, -0.125]],\n",
        "    [[0.25, -0.25, 0.0], [0.25, -0.25, 0.0]],\n",
        "    [[0.5, 0.0, 0.0], [-0.25, -0.25, 0.25], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, 0.0, 0.25], [-0.25, 0.0, 0.25]],\n",
        "    [[0.125, 0.125, 0.125], [-0.125, 0.125, 0.125]],\n",
        "    [[-0.125, 0.125, 0.125]],\n",
        "    [[0.5, 0.0, -0.0], [0.25, 0.25, 0.25], [0.125, 0.125, 0.125]],\n",
        "    [[0.125, -0.125, 0.125], [-0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.0, -0.25], [0.25, 0.0, 0.25]],\n",
        "    [[0.125, -0.125, 0.125]],\n",
        "    [[-0.25, -0.25, 0.0], [0.25, 0.25, -0.0]],\n",
        "    [[-0.125, -0.125, 0.125]],\n",
        "    [[0.125, 0.125, 0.125]],\n",
        "    [[0, 0, 0]]]\n",
        "# pylint: enable=line-too-long\n",
        "\n",
        "\n",
        "def create_table_neighbour_code_to_surface_area(spacing_mm):\n",
        "  \"\"\"Returns an array mapping neighbourhood code to the surface elements area.\n",
        "\n",
        "  Note that the normals encode the initial surface area. This function computes\n",
        "  the area corresponding to the given `spacing_mm`.\n",
        "\n",
        "  Args:\n",
        "    spacing_mm: 3-element list-like structure. Voxel spacing in x0, x1 and x2\n",
        "      direction.\n",
        "  \"\"\"\n",
        "  # compute the area for all 256 possible surface elements\n",
        "  # (given a 2x2x2 neighbourhood) according to the spacing_mm\n",
        "  neighbour_code_to_surface_area = np.zeros([256])\n",
        "  for code in range(256):\n",
        "    normals = np.array(_NEIGHBOUR_CODE_TO_NORMALS[code])\n",
        "    sum_area = 0\n",
        "    for normal_idx in range(normals.shape[0]):\n",
        "      # normal vector\n",
        "      n = np.zeros([3])\n",
        "      n[0] = normals[normal_idx, 0] * spacing_mm[1] * spacing_mm[2]\n",
        "      n[1] = normals[normal_idx, 1] * spacing_mm[0] * spacing_mm[2]\n",
        "      n[2] = normals[normal_idx, 2] * spacing_mm[0] * spacing_mm[1]\n",
        "      area = np.linalg.norm(n)\n",
        "      sum_area += area\n",
        "    neighbour_code_to_surface_area[code] = sum_area\n",
        "\n",
        "  return neighbour_code_to_surface_area\n",
        "\n",
        "\n",
        "# In the neighbourhood, points are ordered: top left, top right, bottom left,\n",
        "# bottom right.\n",
        "ENCODE_NEIGHBOURHOOD_2D_KERNEL = np.array([[8, 4], [2, 1]])\n",
        "\n",
        "\n",
        "def create_table_neighbour_code_to_contour_length(spacing_mm):\n",
        "  \"\"\"Returns an array mapping neighbourhood code to the contour length.\n",
        "\n",
        "  For the list of possible cases and their figures, see page 38 from:\n",
        "  https://nccastaff.bournemouth.ac.uk/jmacey/MastersProjects/MSc14/06/thesis.pdf\n",
        "\n",
        "  In 2D, each point has 4 neighbors. Thus, are 16 configurations. A\n",
        "  configuration is encoded with '1' meaning \"inside the object\" and '0' \"outside\n",
        "  the object\". The points are ordered: top left, top right, bottom left, bottom\n",
        "  right.\n",
        "\n",
        "  The x0 axis is assumed vertical downward, and the x1 axis is horizontal to the\n",
        "  right:\n",
        "   (0, 0) --> (0, 1)\n",
        "     |\n",
        "   (1, 0)\n",
        "\n",
        "  Args:\n",
        "    spacing_mm: 2-element list-like structure. Voxel spacing in x0 and x1\n",
        "      directions.\n",
        "  \"\"\"\n",
        "  neighbour_code_to_contour_length = np.zeros([16])\n",
        "\n",
        "  vertical = spacing_mm[0]\n",
        "  horizontal = spacing_mm[1]\n",
        "  diag = 0.5 * math.sqrt(spacing_mm[0]**2 + spacing_mm[1]**2)\n",
        "  # pyformat: disable\n",
        "  neighbour_code_to_contour_length[int(\"00\"\n",
        "                                       \"01\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"00\"\n",
        "                                       \"10\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"00\"\n",
        "                                       \"11\", 2)] = horizontal\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"01\"\n",
        "                                       \"00\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"01\"\n",
        "                                       \"01\", 2)] = vertical\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"01\"\n",
        "                                       \"10\", 2)] = 2*diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"01\"\n",
        "                                       \"11\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"10\"\n",
        "                                       \"00\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"10\"\n",
        "                                       \"01\", 2)] = 2*diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"10\"\n",
        "                                       \"10\", 2)] = vertical\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"10\"\n",
        "                                       \"11\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"11\"\n",
        "                                       \"00\", 2)] = horizontal\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"11\"\n",
        "                                       \"01\", 2)] = diag\n",
        "\n",
        "  neighbour_code_to_contour_length[int(\"11\"\n",
        "                                       \"10\", 2)] = diag\n",
        "  # pyformat: enable\n",
        "\n",
        "  return neighbour_code_to_contour_length"
      ],
      "metadata": {
        "id": "ROi3Ik3Sv68O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# from . import lookup_tables\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "def _assert_is_numpy_array(name, array):\n",
        "  \"\"\"Raises an exception if `array` is not a numpy array.\"\"\"\n",
        "  if not isinstance(array, np.ndarray):\n",
        "    raise ValueError(\"The argument {!r} should be a numpy array, not a \"\n",
        "                     \"{}\".format(name, type(array)))\n",
        "\n",
        "\n",
        "def _check_nd_numpy_array(name, array, num_dims):\n",
        "  \"\"\"Raises an exception if `array` is not a `num_dims`-D numpy array.\"\"\"\n",
        "  if len(array.shape) != num_dims:\n",
        "    raise ValueError(\"The argument {!r} should be a {}D array, not of \"\n",
        "                     \"shape {}\".format(name, num_dims, array.shape))\n",
        "\n",
        "\n",
        "def _check_2d_numpy_array(name, array):\n",
        "  _check_nd_numpy_array(name, array, num_dims=2)\n",
        "\n",
        "\n",
        "def _check_3d_numpy_array(name, array):\n",
        "  _check_nd_numpy_array(name, array, num_dims=3)\n",
        "\n",
        "\n",
        "def _assert_is_bool_numpy_array(name, array):\n",
        "  _assert_is_numpy_array(name, array)\n",
        "  if array.dtype != bool:\n",
        "    raise ValueError(\"The argument {!r} should be a numpy array of type bool, \"\n",
        "                     \"not {}\".format(name, array.dtype))\n",
        "\n",
        "\n",
        "def _compute_bounding_box(mask):\n",
        "  \"\"\"Computes the bounding box of the masks.\n",
        "\n",
        "  This function generalizes to arbitrary number of dimensions great or equal\n",
        "  to 1.\n",
        "\n",
        "  Args:\n",
        "    mask: The 2D or 3D numpy mask, where '0' means background and non-zero means\n",
        "      foreground.\n",
        "\n",
        "  Returns:\n",
        "    A tuple:\n",
        "     - The coordinates of the first point of the bounding box (smallest on all\n",
        "       axes), or `None` if the mask contains only zeros.\n",
        "     - The coordinates of the second point of the bounding box (greatest on all\n",
        "       axes), or `None` if the mask contains only zeros.\n",
        "  \"\"\"\n",
        "  num_dims = len(mask.shape)\n",
        "  bbox_min = np.zeros(num_dims, np.int64)\n",
        "  bbox_max = np.zeros(num_dims, np.int64)\n",
        "\n",
        "  # max projection to the x0-axis\n",
        "  proj_0 = np.amax(mask, axis=tuple(range(num_dims))[1:])\n",
        "  idx_nonzero_0 = np.nonzero(proj_0)[0]\n",
        "  if len(idx_nonzero_0) == 0:  # pylint: disable=g-explicit-length-test\n",
        "    return None, None\n",
        "\n",
        "  bbox_min[0] = np.min(idx_nonzero_0)\n",
        "  bbox_max[0] = np.max(idx_nonzero_0)\n",
        "\n",
        "  # max projection to the i-th-axis for i in {1, ..., num_dims - 1}\n",
        "  for axis in range(1, num_dims):\n",
        "    max_over_axes = list(range(num_dims))  # Python 3 compatible\n",
        "    max_over_axes.pop(axis)  # Remove the i-th dimension from the max\n",
        "    max_over_axes = tuple(max_over_axes)  # numpy expects a tuple of ints\n",
        "    proj = np.amax(mask, axis=max_over_axes)\n",
        "    idx_nonzero = np.nonzero(proj)[0]\n",
        "    bbox_min[axis] = np.min(idx_nonzero)\n",
        "    bbox_max[axis] = np.max(idx_nonzero)\n",
        "\n",
        "  return bbox_min, bbox_max\n",
        "\n",
        "\n",
        "def _crop_to_bounding_box(mask, bbox_min, bbox_max):\n",
        "  \"\"\"Crops a 2D or 3D mask to the bounding box specified by `bbox_{min,max}`.\"\"\"\n",
        "  # we need to zeropad the cropped region with 1 voxel at the lower,\n",
        "  # the right (and the back on 3D) sides. This is required to obtain the\n",
        "  # \"full\" convolution result with the 2x2 (or 2x2x2 in 3D) kernel.\n",
        "  # TODO:  This is correct only if the object is interior to the\n",
        "  # bounding box.\n",
        "  cropmask = np.zeros((bbox_max - bbox_min) + 2, np.uint8)\n",
        "\n",
        "  num_dims = len(mask.shape)\n",
        "  # pyformat: disable\n",
        "  if num_dims == 2:\n",
        "    cropmask[0:-1, 0:-1] = mask[bbox_min[0]:bbox_max[0] + 1,\n",
        "                                bbox_min[1]:bbox_max[1] + 1]\n",
        "  elif num_dims == 3:\n",
        "    cropmask[0:-1, 0:-1, 0:-1] = mask[bbox_min[0]:bbox_max[0] + 1,\n",
        "                                      bbox_min[1]:bbox_max[1] + 1,\n",
        "                                      bbox_min[2]:bbox_max[2] + 1]\n",
        "  # pyformat: enable\n",
        "  else:\n",
        "    assert False\n",
        "\n",
        "  return cropmask\n",
        "\n",
        "\n",
        "def _sort_distances_surfels(distances, surfel_areas):\n",
        "  \"\"\"Sorts the two list with respect to the tuple of (distance, surfel_area).\n",
        "\n",
        "  Args:\n",
        "    distances: The distances from A to B (e.g. `distances_gt_to_pred`).\n",
        "    surfel_areas: The surfel areas for A (e.g. `surfel_areas_gt`).\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the sorted (distances, surfel_areas).\n",
        "  \"\"\"\n",
        "  sorted_surfels = np.array(sorted(zip(distances, surfel_areas)))\n",
        "  return sorted_surfels[:, 0], sorted_surfels[:, 1]\n",
        "\n",
        "\n",
        "def compute_surface_distances(mask_gt,\n",
        "                              mask_pred,\n",
        "                              spacing_mm):\n",
        "\n",
        "  # The terms used in this function are for the 3D case. In particular, surface\n",
        "  # in 2D stands for contours in 3D. The surface elements in 3D correspond to\n",
        "  # the line elements in 2D.\n",
        "\n",
        "  _assert_is_bool_numpy_array(\"mask_gt\", mask_gt)\n",
        "  _assert_is_bool_numpy_array(\"mask_pred\", mask_pred)\n",
        "\n",
        "  if not len(mask_gt.shape) == len(mask_pred.shape) == len(spacing_mm):\n",
        "    raise ValueError(\"The arguments must be of compatible shape. Got mask_gt \"\n",
        "                     \"with {} dimensions ({}) and mask_pred with {} dimensions \"\n",
        "                     \"({}), while the spacing_mm was {} elements.\".format(\n",
        "                         len(mask_gt.shape),\n",
        "                         mask_gt.shape, len(mask_pred.shape), mask_pred.shape,\n",
        "                         len(spacing_mm)))\n",
        "\n",
        "  num_dims = len(spacing_mm)\n",
        "  if num_dims == 2:\n",
        "    _check_2d_numpy_array(\"mask_gt\", mask_gt)\n",
        "    _check_2d_numpy_array(\"mask_pred\", mask_pred)\n",
        "\n",
        "    # compute the area for all 16 possible surface elements\n",
        "    # (given a 2x2 neighbourhood) according to the spacing_mm\n",
        "    neighbour_code_to_surface_area = (\n",
        "        create_table_neighbour_code_to_contour_length(spacing_mm))\n",
        "    kernel = ENCODE_NEIGHBOURHOOD_2D_KERNEL\n",
        "    full_true_neighbours = 0b1111\n",
        "  elif num_dims == 3:\n",
        "    _check_3d_numpy_array(\"mask_gt\", mask_gt)\n",
        "    _check_3d_numpy_array(\"mask_pred\", mask_pred)\n",
        "\n",
        "    # compute the area for all 256 possible surface elements\n",
        "    # (given a 2x2x2 neighbourhood) according to the spacing_mm\n",
        "    neighbour_code_to_surface_area = (\n",
        "        create_table_neighbour_code_to_surface_area(spacing_mm))\n",
        "    kernel = ENCODE_NEIGHBOURHOOD_3D_KERNEL\n",
        "    full_true_neighbours = 0b11111111\n",
        "  else:\n",
        "    raise ValueError(\"Only 2D and 3D masks are supported, not \"\n",
        "                     \"{}D.\".format(num_dims))\n",
        "\n",
        "  # compute the bounding box of the masks to trim the volume to the smallest\n",
        "  # possible processing subvolume\n",
        "  bbox_min, bbox_max = _compute_bounding_box(mask_gt | mask_pred)\n",
        "  # Both the min/max bbox are None at the same time, so we only check one.\n",
        "  if bbox_min is None:\n",
        "    return {\n",
        "        \"distances_gt_to_pred\": np.array([]),\n",
        "        \"distances_pred_to_gt\": np.array([]),\n",
        "        \"surfel_areas_gt\": np.array([]),\n",
        "        \"surfel_areas_pred\": np.array([]),\n",
        "    }\n",
        "\n",
        "  # crop the processing subvolume.\n",
        "  cropmask_gt = _crop_to_bounding_box(mask_gt, bbox_min, bbox_max)\n",
        "  cropmask_pred = _crop_to_bounding_box(mask_pred, bbox_min, bbox_max)\n",
        "\n",
        "  # compute the neighbour code (local binary pattern) for each voxel\n",
        "  # the resulting arrays are spacially shifted by minus half a voxel in each\n",
        "  # axis.\n",
        "  # i.e. the points are located at the corners of the original voxels\n",
        "  neighbour_code_map_gt = ndimage.filters.correlate(\n",
        "      cropmask_gt.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
        "  neighbour_code_map_pred = ndimage.filters.correlate(\n",
        "      cropmask_pred.astype(np.uint8), kernel, mode=\"constant\", cval=0)\n",
        "\n",
        "  # create masks with the surface voxels\n",
        "  borders_gt = ((neighbour_code_map_gt != 0) &\n",
        "                (neighbour_code_map_gt != full_true_neighbours))\n",
        "  borders_pred = ((neighbour_code_map_pred != 0) &\n",
        "                  (neighbour_code_map_pred != full_true_neighbours))\n",
        "\n",
        "  # compute the distance transform (closest distance of each voxel to the\n",
        "  # surface voxels)\n",
        "  if borders_gt.any():\n",
        "    distmap_gt = ndimage.morphology.distance_transform_edt(\n",
        "        ~borders_gt, sampling=spacing_mm)\n",
        "  else:\n",
        "    distmap_gt = np.Inf * np.ones(borders_gt.shape)\n",
        "\n",
        "  if borders_pred.any():\n",
        "    distmap_pred = ndimage.morphology.distance_transform_edt(\n",
        "        ~borders_pred, sampling=spacing_mm)\n",
        "  else:\n",
        "    distmap_pred = np.Inf * np.ones(borders_pred.shape)\n",
        "\n",
        "  # compute the area of each surface element\n",
        "  surface_area_map_gt = neighbour_code_to_surface_area[neighbour_code_map_gt]\n",
        "  surface_area_map_pred = neighbour_code_to_surface_area[\n",
        "      neighbour_code_map_pred]\n",
        "\n",
        "  # create a list of all surface elements with distance and area\n",
        "  distances_gt_to_pred = distmap_pred[borders_gt]\n",
        "  distances_pred_to_gt = distmap_gt[borders_pred]\n",
        "  surfel_areas_gt = surface_area_map_gt[borders_gt]\n",
        "  surfel_areas_pred = surface_area_map_pred[borders_pred]\n",
        "\n",
        "  # sort them by distance\n",
        "  if distances_gt_to_pred.shape != (0,):\n",
        "    distances_gt_to_pred, surfel_areas_gt = _sort_distances_surfels(\n",
        "        distances_gt_to_pred, surfel_areas_gt)\n",
        "\n",
        "  if distances_pred_to_gt.shape != (0,):\n",
        "    distances_pred_to_gt, surfel_areas_pred = _sort_distances_surfels(\n",
        "        distances_pred_to_gt, surfel_areas_pred)\n",
        "\n",
        "  return {\n",
        "      \"distances_gt_to_pred\": distances_gt_to_pred,\n",
        "      \"distances_pred_to_gt\": distances_pred_to_gt,\n",
        "      \"surfel_areas_gt\": surfel_areas_gt,\n",
        "      \"surfel_areas_pred\": surfel_areas_pred,\n",
        "  }\n",
        "\n",
        "\n",
        "def compute_average_surface_distance(surface_distances):\n",
        "  distances_gt_to_pred = surface_distances[\"distances_gt_to_pred\"]\n",
        "  distances_pred_to_gt = surface_distances[\"distances_pred_to_gt\"]\n",
        "  surfel_areas_gt = surface_distances[\"surfel_areas_gt\"]\n",
        "  surfel_areas_pred = surface_distances[\"surfel_areas_pred\"]\n",
        "  average_distance_gt_to_pred = (\n",
        "      np.sum(distances_gt_to_pred * surfel_areas_gt) / np.sum(surfel_areas_gt))\n",
        "  average_distance_pred_to_gt = (\n",
        "      np.sum(distances_pred_to_gt * surfel_areas_pred) /\n",
        "      np.sum(surfel_areas_pred))\n",
        "  return (average_distance_gt_to_pred, average_distance_pred_to_gt)\n",
        "\n",
        "def compute_average_symmetric_surface_distance(surface_distances):\n",
        "  distances_gt_to_pred = surface_distances[\"distances_gt_to_pred\"]\n",
        "  distances_pred_to_gt = surface_distances[\"distances_pred_to_gt\"]\n",
        "  surfel_areas_gt = surface_distances[\"surfel_areas_gt\"]\n",
        "  surfel_areas_pred = surface_distances[\"surfel_areas_pred\"]\n",
        "\n",
        "  assd = (np.sum(distances_gt_to_pred * surfel_areas_gt) + np.sum(distances_pred_to_gt * surfel_areas_pred))/(np.sum(surfel_areas_gt)+np.sum(surfel_areas_pred))\n",
        "  return assd\n",
        "\n",
        "\n",
        "def compute_robust_hausdorff(surface_distances, percent):\n",
        "  distances_gt_to_pred = surface_distances[\"distances_gt_to_pred\"]\n",
        "  distances_pred_to_gt = surface_distances[\"distances_pred_to_gt\"]\n",
        "  surfel_areas_gt = surface_distances[\"surfel_areas_gt\"]\n",
        "  surfel_areas_pred = surface_distances[\"surfel_areas_pred\"]\n",
        "  if len(distances_gt_to_pred) > 0:  # pylint: disable=g-explicit-length-test\n",
        "    surfel_areas_cum_gt = np.cumsum(surfel_areas_gt) / np.sum(surfel_areas_gt)\n",
        "    idx = np.searchsorted(surfel_areas_cum_gt, percent/100.0)\n",
        "    perc_distance_gt_to_pred = distances_gt_to_pred[\n",
        "        min(idx, len(distances_gt_to_pred)-1)]\n",
        "  else:\n",
        "    perc_distance_gt_to_pred = np.Inf\n",
        "\n",
        "  if len(distances_pred_to_gt) > 0:  # pylint: disable=g-explicit-length-test\n",
        "    surfel_areas_cum_pred = (np.cumsum(surfel_areas_pred) /\n",
        "                             np.sum(surfel_areas_pred))\n",
        "    idx = np.searchsorted(surfel_areas_cum_pred, percent/100.0)\n",
        "    perc_distance_pred_to_gt = distances_pred_to_gt[\n",
        "        min(idx, len(distances_pred_to_gt)-1)]\n",
        "  else:\n",
        "    perc_distance_pred_to_gt = np.Inf\n",
        "\n",
        "  return max(perc_distance_gt_to_pred, perc_distance_pred_to_gt)\n",
        "\n",
        "\n",
        "def compute_surface_overlap_at_tolerance(surface_distances, tolerance_mm):\n",
        "  distances_gt_to_pred = surface_distances[\"distances_gt_to_pred\"]\n",
        "  distances_pred_to_gt = surface_distances[\"distances_pred_to_gt\"]\n",
        "  surfel_areas_gt = surface_distances[\"surfel_areas_gt\"]\n",
        "  surfel_areas_pred = surface_distances[\"surfel_areas_pred\"]\n",
        "  rel_overlap_gt = (\n",
        "      np.sum(surfel_areas_gt[distances_gt_to_pred <= tolerance_mm]) /\n",
        "      np.sum(surfel_areas_gt))\n",
        "  rel_overlap_pred = (\n",
        "      np.sum(surfel_areas_pred[distances_pred_to_gt <= tolerance_mm]) /\n",
        "      np.sum(surfel_areas_pred))\n",
        "  return (rel_overlap_gt, rel_overlap_pred)\n",
        "\n",
        "\n",
        "def compute_surface_dice_at_tolerance(surface_distances, tolerance_mm):\n",
        "  distances_gt_to_pred = surface_distances[\"distances_gt_to_pred\"]\n",
        "  distances_pred_to_gt = surface_distances[\"distances_pred_to_gt\"]\n",
        "  surfel_areas_gt = surface_distances[\"surfel_areas_gt\"]\n",
        "  surfel_areas_pred = surface_distances[\"surfel_areas_pred\"]\n",
        "  overlap_gt = np.sum(surfel_areas_gt[distances_gt_to_pred <= tolerance_mm])\n",
        "  overlap_pred = np.sum(surfel_areas_pred[distances_pred_to_gt <= tolerance_mm])\n",
        "  surface_dice = (overlap_gt + overlap_pred) / (\n",
        "      np.sum(surfel_areas_gt) + np.sum(surfel_areas_pred))\n",
        "  return surface_dice\n",
        "\n",
        "\n",
        "def compute_dice_coefficient(mask_gt, mask_pred):\n",
        "  volume_sum = mask_gt.sum() + mask_pred.sum()\n",
        "  if volume_sum == 0:\n",
        "    return np.NaN\n",
        "  volume_intersect = (mask_gt & mask_pred).sum()\n",
        "  return 2*volume_intersect / volume_sum"
      ],
      "metadata": {
        "id": "ZQ6tSkMDv6-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import h5py,cv2\n",
        "import math\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from medpy import metric\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from skimage.measure import label\n",
        "\n",
        "import sys\n",
        "\n",
        "FLAGS = argparse.Namespace(\n",
        "    root_path='/content/2018LA_Seg_Training Set/',\n",
        "    model='test',\n",
        "    normalization='batchnorm',\n",
        "    epoch_num=3400,\n",
        "    spacing=1,\n",
        "    post=True,\n",
        "    has_triup=True\n",
        ")\n",
        "\n",
        "\n",
        "snapshot_path = '/content/SCC_6/SCC'\n",
        "test_save_path = \"/content/model/content/prediction/\"\n",
        "\n",
        "if not os.path.exists(test_save_path):\n",
        "    os.makedirs(test_save_path)\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "patch_shape=(80, 112,112)\n",
        "\n",
        "with open( '/content/2018LA_Seg_Training Set/test.txt', 'r') as f:\n",
        "    image_list = f.readlines()\n",
        "    image_list = [FLAGS.root_path + item.replace('\\n', '') + \"/mri_norm2.h5\" for item in image_list]\n",
        "\n",
        "def test_calculate_metric(epoch_num):\n",
        "    encoder= VNet_Encoder(n_channels=1,normalization='batchnorm', has_dropout=False).cuda()\n",
        "    seg_decoder1 = MainDecoder(n_classes=2, n_filters=16, normalization='batchnorm', has_dropout=False).cuda()\n",
        "    if FLAGS.has_triup:\n",
        "        seg_decoder2 = TriupDecoder(n_classes=num_classes, n_filters=16, normalization=FLAGS.normalization,has_dropout=True).cuda()\n",
        "    else:\n",
        "        seg_decoder2 = MainDecoder(n_classes=num_classes, n_filters=16, normalization=FLAGS.normalization,has_dropout=True).cuda()\n",
        "    save_mode_path = os.path.join(snapshot_path, 'iter_' + str(epoch_num) + '.pth')\n",
        "    pre_trained_model = torch.load(save_mode_path)\n",
        "    encoder.load_state_dict(pre_trained_model['encoder_state_dict'])\n",
        "    seg_decoder1.load_state_dict(pre_trained_model['seg_decoder_1_state_dict'])\n",
        "    seg_decoder2.load_state_dict(pre_trained_model['seg_decoder_2_state_dict'])\n",
        "    print(\"init weight from {}\".format(save_mode_path))\n",
        "\n",
        "\n",
        "    avg_metric = dist_test_all_case(encoder,seg_decoder1, seg_decoder2, image_list, num_classes=num_classes,\n",
        "                                        save_result=True, test_save_path=test_save_path,\n",
        "                                        has_post=FLAGS.post)\n",
        "\n",
        "\n",
        "    return avg_metric\n",
        "\n",
        "\n",
        "def dist_test_all_case(encoder,seg_decoder1, seg_decoder2, image_list, num_classes, save_result=True, test_save_path=None, has_post=False):\n",
        "    total_metric = 0.0\n",
        "    metric_dict = OrderedDict()\n",
        "    metric_dict['name'] = list()\n",
        "    metric_dict['dice'] = list()\n",
        "    metric_dict['jaccard'] = list()\n",
        "    metric_dict['asd'] = list()\n",
        "    metric_dict['95hd'] = list()\n",
        "\n",
        "    for image_path in tqdm(image_list):\n",
        "        case_name = image_path.split('/')[-2]\n",
        "        print(case_name)\n",
        "        id = image_path.split('/')[-1]\n",
        "\n",
        "        h5f = h5py.File(image_path, 'r')\n",
        "        image = h5f['image'][:]\n",
        "        label = h5f['label'][:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction, score_map = test_single_case_patch(encoder,seg_decoder1, seg_decoder2, image, 18,18, 4, patch_shape , num_classes=num_classes)\n",
        "\n",
        "        if np.sum(prediction) == 0:\n",
        "            single_metric = (0,0,0,0,0,0)\n",
        "        else:\n",
        "            if has_post:\n",
        "                print('post')\n",
        "                prediction = getLargestCC(prediction)\n",
        "            single_metric = calculate_metric_percase(prediction, label[:], space=FLAGS.spacing)\n",
        "            metric_dict['name'].append(case_name)\n",
        "            metric_dict['dice'].append(single_metric[0])\n",
        "            metric_dict['jaccard'].append(single_metric[1])\n",
        "            metric_dict['asd'].append(single_metric[2])\n",
        "            metric_dict['95hd'].append(single_metric[3])\n",
        "            print(case_name,single_metric)\n",
        "\n",
        "\n",
        "        if save_result:\n",
        "            test_save_path_temp = os.path.join(test_save_path, case_name)\n",
        "            if not os.path.exists(test_save_path_temp):\n",
        "                os.makedirs(test_save_path_temp)\n",
        "\n",
        "            nib.save(nib.Nifti1Image(prediction.astype(np.uint8), np.eye(4)), test_save_path_temp + '/' + case_name + '/' + id + \"_pred.nii.gz\")\n",
        "            nib.save(nib.Nifti1Image(image.astype(np.float32), np.eye(4)), test_save_path_temp + '/' + case_name + '/' +  id + \"_img.nii.gz\")\n",
        "            nib.save(nib.Nifti1Image(label.astype(np.uint8), np.eye(4)), test_save_path_temp + '/' + case_name + '/' + id + \"_gt.nii.gz\")\n",
        "\n",
        "    avg_metric = total_metric / len(image_list)\n",
        "    print(metric_dict)\n",
        "    metric_csv = pd.DataFrame(metric_dict)\n",
        "    if has_post:\n",
        "        metric_csv.to_csv(test_save_path + '/metric_post_' + str(FLAGS.epoch_num) + '.csv', index=False)\n",
        "    else:\n",
        "        metric_csv.to_csv(test_save_path + '/metric_'+str(FLAGS.epoch_num)+'.csv', index=False)\n",
        "    print('average metric is {}'.format(avg_metric))\n",
        "\n",
        "    return avg_metric\n",
        "\n",
        "def test_single_case_patch(encoder,seg_decoder1, seg_decoder2, image, stride_x,stride_y, stride_z, patch_size, num_classes=1):\n",
        "    w, h, d = image.shape\n",
        "\n",
        "    add_pad = False\n",
        "    if w < patch_size[0]:\n",
        "        w_pad = patch_size[0]-w\n",
        "        add_pad = True\n",
        "    else:\n",
        "        w_pad = 0\n",
        "    if h < patch_size[1]:\n",
        "        h_pad = patch_size[1]-h\n",
        "        add_pad = True\n",
        "    else:\n",
        "        h_pad = 0\n",
        "    if d < patch_size[2]:\n",
        "        d_pad = patch_size[2]-d\n",
        "        add_pad = True\n",
        "    else:\n",
        "        d_pad = 0\n",
        "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
        "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
        "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
        "    if add_pad:\n",
        "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
        "    ww,hh,dd = image.shape\n",
        "\n",
        "    sx = math.ceil((ww - patch_size[0]) / stride_x) + 1\n",
        "    sy = math.ceil((hh - patch_size[1]) / stride_y) + 1\n",
        "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
        "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
        "    cnt = np.zeros(image.shape).astype(np.float32)\n",
        "\n",
        "\n",
        "    for x in range(0, sx):\n",
        "        xs = min(stride_x*x, ww-patch_size[0])\n",
        "        for y in range(0, sy):\n",
        "            ys = min(stride_y * y,hh-patch_size[1])\n",
        "            for z in range(0, sz):\n",
        "                encoder.eval()\n",
        "                seg_decoder1.eval()\n",
        "                seg_decoder2.eval()\n",
        "                zs = min(stride_z * z, dd-patch_size[2])\n",
        "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
        "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
        "                test_patch = torch.from_numpy(test_patch).cuda()\n",
        "\n",
        "                features = encoder(test_patch)\n",
        "                y_1 = seg_decoder1(features)\n",
        "                y_2 = seg_decoder2(features)\n",
        "\n",
        "                y_1_soft = F.softmax(y_1, dim=1)\n",
        "                y_2_soft = F.softmax(y_2, dim=1)\n",
        "                y = torch.mean(torch.stack([y_1_soft, y_2_soft]), dim=0)\n",
        "                y = y.cpu().data.numpy()\n",
        "                y = y[0,:,:,:,:]\n",
        "\n",
        "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
        "                  = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y\n",
        "                cnt[xs:xs + patch_size[0], ys:ys + patch_size[1], zs:zs + patch_size[2]] \\\n",
        "                    = cnt[xs:xs + patch_size[0], ys:ys + patch_size[1], zs:zs + patch_size[2]] + 1\n",
        "\n",
        "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
        "    label_map = np.argmax(score_map, axis = 0)\n",
        "    if add_pad:\n",
        "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
        "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
        "\n",
        "    return label_map, score_map\n",
        "\n",
        "def cal_dice(prediction, label, num=2):\n",
        "    total_dice = np.zeros(num-1)\n",
        "    for i in range(1, num):\n",
        "        prediction_tmp = (prediction==i)\n",
        "        label_tmp = (label==i)\n",
        "        prediction_tmp = prediction_tmp.astype(np.float)\n",
        "        label_tmp = label_tmp.astype(np.float)\n",
        "\n",
        "        dice = 2 * np.sum(prediction_tmp * label_tmp) / (np.sum(prediction_tmp) + np.sum(label_tmp))\n",
        "        total_dice[i - 1] += dice\n",
        "\n",
        "    return total_dice\n",
        "\n",
        "\n",
        "def calculate_metric_percase(pred, gt, space=0.625):\n",
        "    dice_medpy = metric.binary.dc(pred,gt)\n",
        "    jc_medpy = metric.binary.jc(pred,gt)\n",
        "    asd_score = metric.binary.asd(pred, gt)\n",
        "    hd95_score = metric.binary.hd95(pred, gt)\n",
        "    return dice_medpy, jc_medpy, asd_score, hd95_score\n",
        "\n",
        "\n",
        "def normalized_surface_dice(pred, gt, voxelspacing=None):\n",
        "    surface_dis = compute_surface_distances(gt.astype(bool),\n",
        "                                                        pred.astype(bool),\n",
        "                                                        spacing_mm=(voxelspacing, voxelspacing, voxelspacing))\n",
        "    surface_dice = compute_surface_dice_at_tolerance(surface_dis, 1)\n",
        "    return surface_dice\n",
        "\n",
        "\n",
        "def getLargestCC(segmentation):\n",
        "    labels = label(segmentation)\n",
        "    assert(labels.max() != 0)\n",
        "    largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
        "    largestCC=np.array(largestCC,dtype=int)\n",
        "\n",
        "    return largestCC\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    metric = test_calculate_metric(FLAGS.epoch_num)\n"
      ],
      "metadata": {
        "id": "mdGIGk7yvVkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/model"
      ],
      "metadata": {
        "id": "WzPpruMqBcRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}